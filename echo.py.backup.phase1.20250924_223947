#!/usr/bin/env python3
"""
Echo Brain Unified Service - Refactored Architecture
Consolidates 5 fragmented Echo services into single intelligent router
Implements dynamic model escalation from 1B to 70B parameters
Includes Board of Directors decision tracking system
"""

import asyncio
import aiohttp
import logging
import json
import psycopg2
import uuid
import re
import subprocess
import os
import tempfile
import time
from datetime import datetime
from typing import Dict, List, Optional
from fastapi import FastAPI, HTTPException, WebSocket, BackgroundTasks, Depends
from fastapi.responses import StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import uvicorn
from echo_brain_thoughts import echo_brain

# Board of Directors imports
from routing.service_registry import ServiceRegistry
from routing.request_logger import RequestLogger
from routing.feedback_system import FeedbackProcessor, UserFeedback, FeedbackType
from routing.user_preferences import UserPreferences, PreferenceType
from routing.knowledge_manager import KnowledgeManager, create_simple_knowledge_manager
from routing.sandbox_executor import SandboxExecutor, create_strict_sandbox
from board_api import create_board_api
from model_manager import (
    get_model_manager, ModelManagementRequest, ModelManagementResponse,
    ModelOperation, ModelInfo
)
from routing.auth_middleware import get_current_user
from model_decision_engine import get_decision_engine
from telegram_integration import telegram_router
from veteran_guardian_endpoints import veteran_router
from agent_development_endpoints import agent_dev_router
from quality_monitoring import quality_monitor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Request/Response Models
class QueryRequest(BaseModel):
    query: str
    context: Optional[Dict] = {}
    intelligence_level: Optional[str] = "auto"
    user_id: Optional[str] = "default"  # For conversation tracking
    conversation_id: Optional[str] = None

class QueryResponse(BaseModel):
    response: str
    model_used: str
    intelligence_level: str
    processing_time: float
    escalation_path: List[str]
    requires_clarification: bool = False
    clarifying_questions: List[str] = []
    conversation_id: str
    intent: Optional[str] = None
    confidence: float = 0.0

class ExecuteRequest(BaseModel):
    command: str
    context: Optional[Dict] = {}
    conversation_id: Optional[str] = None
    user_id: Optional[str] = "default"
    safe_mode: bool = True

class ExecuteResponse(BaseModel):
    command: str
    success: bool
    output: str
    error: Optional[str] = None
    exit_code: int
    processing_time: float
    conversation_id: str
    safety_checks: Dict[str, bool]

class TestRequest(BaseModel):
    target: str
    test_type: Optional[str] = "universal"
    conversation_id: Optional[str] = None
    user_id: Optional[str] = "default"

class TowerTestingFramework:
    """Tower Testing Framework Integration for Echo Brain"""
    
    def __init__(self):
        self.framework_path = "/home/patrick/Documents"
        self.tower_script = os.path.join(self.framework_path, "tower")
        self.universal_test_script = os.path.join(self.framework_path, "tower_universal_test.sh")
        self.debug_tools_script = os.path.join(self.framework_path, "tower_debug_tools.sh")
        self.tower_host = "localhost"
        
        # Ensure scripts are executable
        for script in [self.tower_script, self.universal_test_script, self.debug_tools_script]:
            if os.path.exists(script):
                os.chmod(script, 0o755)
    
    async def run_universal_test(self, target: str) -> Dict:
        """Run universal test on a target service"""
        logger.info(f"Running universal test on {target}")
        
        try:
            start_time = asyncio.get_event_loop().time()
            
            # Execute universal test script
            result = subprocess.run(
                [self.universal_test_script, target],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            return {
                "success": result.returncode == 0,
                "target": target,
                "output": result.stdout,
                "error": result.stderr if result.stderr else None,
                "exit_code": result.returncode,
                "processing_time": processing_time,
                "test_type": "universal"
            }
            
        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "target": target,
                "output": "",
                "error": "Test timed out after 60 seconds",
                "exit_code": -1,
                "processing_time": 60.0,
                "test_type": "universal"
            }
        except Exception as e:
            return {
                "success": False,
                "target": target,
                "output": "",
                "error": str(e),
                "exit_code": -1,
                "processing_time": 0.0,
                "test_type": "universal"
            }
    
    async def run_debug_analysis(self, target: str) -> Dict:
        """Run debug analysis on a target service"""
        logger.info(f"Running debug analysis on {target}")
        
        try:
            start_time = asyncio.get_event_loop().time()
            
            # Execute debug tools script
            result = subprocess.run(
                [self.debug_tools_script, target],
                capture_output=True,
                text=True,
                timeout=120  # Debug takes longer
            )
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            return {
                "success": result.returncode == 0,
                "target": target,
                "output": result.stdout,
                "error": result.stderr if result.stderr else None,
                "exit_code": result.returncode,
                "processing_time": processing_time,
                "test_type": "debug"
            }
            
        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "target": target,
                "output": "",
                "error": "Debug analysis timed out after 120 seconds",
                "exit_code": -1,
                "processing_time": 120.0,
                "test_type": "debug"
            }
        except Exception as e:
            return {
                "success": False,
                "target": target,
                "output": "",
                "error": str(e),
                "exit_code": -1,
                "processing_time": 0.0,
                "test_type": "debug"
            }
    
    async def run_tower_command(self, command: str, args: List[str] = None) -> Dict:
        """Run a tower framework command"""
        if args is None:
            args = []
        
        try:
            start_time = asyncio.get_event_loop().time()
            
            cmd = [self.tower_script, command] + args
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=180
            )
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            return {
                "success": result.returncode == 0,
                "command": " ".join(cmd),
                "output": result.stdout,
                "error": result.stderr if result.stderr else None,
                "exit_code": result.returncode,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "success": False,
                "command": " ".join([self.tower_script, command] + args),
                "output": "",
                "error": str(e),
                "exit_code": -1,
                "processing_time": 0.0
            }

class SafeShellExecutor:
    """Safe shell command execution with security controls"""
    
    def __init__(self):
        # Allowed commands for safe mode
        self.safe_commands = {
            'ls', 'pwd', 'echo', 'cat', 'head', 'tail', 'grep', 'find',
            'ps', 'top', 'df', 'free', 'uptime', 'whoami', 'id', 'date',
            'curl', 'wget', 'nc', 'ping', 'nmap', 'systemctl', 'journalctl',
            'git', 'docker', 'python3', 'pip3', 'npm', 'node', 'pnpm'
        }
        
        # SECURITY FIX: Enhanced dangerous patterns to block including directory traversal
        self.dangerous_patterns = [
            r'rm\s+-rf?\s*/', r'sudo\s+rm', r'>\s*/dev/', r'dd\s+if=',
            r'mkfs', r'fdisk', r'parted', r'format', r'del\s+/[qsf]',
            r'shutdown', r'reboot', r'halt', r'init\s+[06]',
            r':\(\)\{', r'fork\s*\(', r'while\s*true', r'yes\s*\|',
            # Directory traversal patterns
            r'\.\./', r'\.\.\\', r'\.\.%2f', r'\.\.%5c',
            r'%2e%2e%2f', r'%2e%2e%5c', r'%252e%252e%252f',
            r'\.\.\/\.\.\/', r'\.\.\\\.\.\\',
            # Path injection patterns
            r'/etc/passwd', r'/etc/shadow', r'/proc/', r'/sys/',
            r'C:\\Windows\\System32', r'C:\\Windows\\system32',
            # Command injection patterns
            r';\s*rm', r'&&\s*rm', r'\|\s*rm', r'`rm', r'\$\(rm',
            r';\s*cat\s+/etc', r'&&\s*cat\s+/etc', r'\|\s*cat\s+/etc'
        ]
    
    def is_command_safe(self, command: str, safe_mode: bool = True) -> tuple[bool, str]:
        """SECURITY FIX: Enhanced command safety validation with path normalization"""
        if not safe_mode:
            return True, "Safe mode disabled"

        # Check for dangerous patterns
        for pattern in self.dangerous_patterns:
            if re.search(pattern, command, re.IGNORECASE):
                return False, f"Command blocked by pattern: {pattern}"

        # SECURITY FIX: Validate file paths in command arguments
        import shlex
        try:
            args = shlex.split(command)
        except ValueError:
            return False, "Invalid command syntax"

        for arg in args:
            # Check for path traversal in arguments
            if self._contains_path_traversal(arg):
                return False, f"Path traversal detected in argument: {arg}"

        # Check if base command is in safe list
        base_cmd = args[0] if args else ""
        if base_cmd not in self.safe_commands:
            return False, f"Command '{base_cmd}' not in safe commands list"

        return True, "Command passed safety checks"

    def _contains_path_traversal(self, path: str) -> bool:
        """SECURITY FIX: Check if path contains directory traversal attempts"""
        import os.path

        # Normalize the path to resolve any relative components
        try:
            normalized = os.path.normpath(path)

            # Check for directory traversal indicators
            traversal_indicators = [
                '..', '../', '..\\', './', '.\\',
                '%2e%2e', '%2e%2e%2f', '%2e%2e%5c',
                '%252e%252e%252f', '%252e%252e%255c'
            ]

            for indicator in traversal_indicators:
                if indicator in path.lower():
                    return True

            # Check if normalized path goes outside intended boundaries
            if normalized.startswith('/etc/') or normalized.startswith('/proc/') or normalized.startswith('/sys/'):
                return True

            if normalized.startswith('C:\\Windows\\') or normalized.startswith('c:\\windows\\'):
                return True

            return False

        except (ValueError, OSError):
            # If path cannot be normalized, consider it suspicious
            return True
    
    async def execute_command(self, command: str, safe_mode: bool = True) -> Dict:
        """Execute a shell command safely"""
        start_time = asyncio.get_event_loop().time()
        
        # Safety check
        is_safe, safety_msg = self.is_command_safe(command, safe_mode)
        safety_checks = {
            "passed_safety_check": is_safe,
            "safe_mode_enabled": safe_mode,
            "safety_message": safety_msg
        }
        
        if not is_safe:
            return {
                "command": command,
                "success": False,
                "output": "",
                "error": f"Command blocked for security: {safety_msg}",
                "exit_code": -1,
                "processing_time": asyncio.get_event_loop().time() - start_time,
                "safety_checks": safety_checks
            }
        
        try:
            # Execute command with timeout
            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                timeout=30,
                cwd=os.path.expanduser("~")
            )
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            return {
                "command": command,
                "success": result.returncode == 0,
                "output": result.stdout,
                "error": result.stderr if result.stderr else None,
                "exit_code": result.returncode,
                "processing_time": processing_time,
                "safety_checks": safety_checks
            }
            
        except subprocess.TimeoutExpired:
            return {
                "command": command,
                "success": False,
                "output": "",
                "error": "Command timed out after 30 seconds",
                "exit_code": -1,
                "processing_time": 30.0,
                "safety_checks": safety_checks
            }
        except Exception as e:
            return {
                "command": command,
                "success": False,
                "output": "",
                "error": str(e),
                "exit_code": -1,
                "processing_time": asyncio.get_event_loop().time() - start_time,
                "safety_checks": safety_checks
            }

class TowerOrchestrator:
    """Integration with Tower Orchestrator Service for task delegation"""
    
    def __init__(self):
        self.orchestrator_url = "http://localhost:8400"
        self.timeout = 30
        
    async def submit_task(self, task_type: str, description: str, requirements: dict = {}, priority: int = 5) -> dict:
        """Submit a task to the orchestrator for delegation"""
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "type": task_type,
                    "description": description,
                    "requirements": requirements,
                    "priority": priority
                }
                
                async with session.post(
                    f"{self.orchestrator_url}/submit_task",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=self.timeout)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return {
                            "success": True,
                            "task_id": result.get("task_id"),
                            "status": result.get("status", "submitted")
                        }
                    else:
                        return {
                            "success": False,
                            "error": f"Orchestrator returned status {response.status}"
                        }
        except Exception as e:
            logger.error(f"Failed to submit task to orchestrator: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def get_available_agents(self) -> dict:
        """Get list of available agents from orchestrator"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.orchestrator_url}/agents",
                    timeout=aiohttp.ClientTimeout(total=self.timeout)
                ) as response:
                    if response.status == 200:
                        agents = await response.json()
                        return {
                            "success": True,
                            "agents": agents
                        }
                    else:
                        return {
                            "success": False,
                            "error": f"Failed to get agents: status {response.status}"
                        }
        except Exception as e:
            logger.error(f"Failed to get agents from orchestrator: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def get_orchestrator_status(self) -> dict:
        """Get orchestrator health and status"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.orchestrator_url}/health",
                    timeout=aiohttp.ClientTimeout(total=self.timeout)
                ) as response:
                    if response.status == 200:
                        status = await response.json()
                        return {
                            "success": True,
                            "status": status
                        }
                    else:
                        return {
                            "success": False,
                            "error": f"Orchestrator health check failed: status {response.status}"
                        }
        except Exception as e:
            logger.error(f"Failed to get orchestrator status: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def communicate_with_service(self, service_name: str, message: str) -> dict:
        """Communicate with other Tower services through orchestrator"""
        # Map service names to Tower service ports
        service_ports = {
            "dashboard": "8080",
            "anime": "8300",
            "agent-manager": "8301",
            "loan-search": "8302",
            "crypto-trader": "8303",
            "deepseek": "8306",
            "kb": "8307",
            "auth": "8088"
        }
        
        service_port = service_ports.get(service_name.lower())
        if not service_port:
            return {
                "success": False,
                "error": f"Unknown service: {service_name}"
            }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"http://localhost:{service_port}/health",
                    timeout=aiohttp.ClientTimeout(total=self.timeout)
                ) as response:
                    if response.status == 200:
                        service_status = await response.json()
                        return {
                            "success": True,
                            "service": service_name,
                            "message": f"Communication established with {service_name}",
                            "status": service_status
                        }
                    else:
                        return {
                            "success": False,
                            "error": f"Service {service_name} not responding (status {response.status})"
                        }
        except Exception as e:
            logger.error(f"Failed to communicate with service {service_name}: {e}")
            return {
                "success": False,
                "error": str(e)
            }

class EchoIntelligenceRouter:
    """Core intelligence routing system for Echo Brain with ML decision engine"""

    def __init__(self):
        self.ollama_url = "http://localhost:11434/api/generate"

        # Initialize decision engine for intelligent model selection
        self.decision_engine = get_decision_engine(database.db_config)

        # Legacy hierarchy for backward compatibility
        self.model_hierarchy = {
            "quick": "tinyllama:latest",        # 1B parameters
            "standard": "llama3.2:3b",          # 3B parameters
            "professional": "mistral:7b",       # 7B parameters
            "expert": "qwen2.5-coder:32b",     # 32B parameters
            "genius": "llama3.1:70b",          # 70B parameters
        }
        self.specialized_models = {
            "coding": "deepseek-coder:latest",  # Updated to use new lightweight version
            "creative": "mixtral:8x7b",
            "analysis": "codellama:70b"
        }
        self.escalation_history = []
        self.decision_history = []  # Track decisions for learning
        
    def analyze_complexity(self, query: str, context: Dict) -> str:
        """Analyze query complexity to determine optimal model"""
        complexity_score = 0.0
        
        # Basic query analysis
        complexity_score += len(query.split()) * 0.3
        complexity_score += query.count('?') * 3
        complexity_score += query.count('.') * 1
        
        # Technical complexity indicators
        technical_terms = [
            'database', 'architecture', 'algorithm', 'implementation',
            'refactor', 'optimization', 'integration', 'system'
        ]
        complexity_score += sum(8 for term in technical_terms if term.lower() in query.lower())
        
        # Programming language detection
        code_terms = ['python', 'javascript', 'sql', 'function', 'class', 'async']
        if any(term in query.lower() for term in code_terms):
            complexity_score += 15
            
        # Context complexity
        if context.get('previous_failures', 0) > 0:
            complexity_score += 20  # Escalate if previous attempts failed
            
        if context.get('user_expertise') == 'expert':
            complexity_score += 10
            
        # Route based on score (adjusted for better escalation)
        if complexity_score < 8:
            return "quick"
        elif complexity_score < 25: 
            return "standard"
        elif complexity_score < 40:
            return "professional"
        elif complexity_score < 60:
            return "expert" 
        else:
            return "genius"
    
    def detect_specialization(self, query: str) -> Optional[str]:
        """Detect if query requires specialized model"""
        query_lower = query.lower()
        
        if any(term in query_lower for term in ['code', 'program', 'function', 'debug']):
            return "coding"
        elif any(term in query_lower for term in ['creative', 'story', 'write', 'imagine']):
            return "creative"  
        elif any(term in query_lower for term in ['analyze', 'data', 'research', 'study']):
            return "analysis"
        return None
    
    def _calculate_complexity_score(self, query: str, context: Dict) -> float:
        """Calculate numerical complexity score for brain visualization"""
        score = 0.0
        
        # Basic query analysis
        score += len(query.split()) * 0.3
        score += query.count('?') * 3
        score += query.count('.') * 1
        
        # Technical complexity indicators (increased scoring)
        technical_terms = [
            'database', 'architecture', 'algorithm', 'implementation',
            'refactor', 'optimization', 'integration', 'system', 'distributed',
            'microservice', 'scalable', 'performance', 'design', 'patterns'
        ]
        score += sum(12 for term in technical_terms if term.lower() in query.lower())
        
        # Programming language detection (increased weight)
        code_terms = ['python', 'javascript', 'sql', 'function', 'class', 'async']
        if any(term in query.lower() for term in code_terms):
            score += 20
            
        # Context complexity
        if context.get('previous_failures', 0) > 0:
            score += 20
            
        return min(score, 100.0)
    
    async def query_model(self, model: str, prompt: str, max_tokens: int = 2048, validate_code: bool = True) -> Dict:
        """Query specific Ollama model with automatic validation and reloading for code generation"""
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "num_predict": max_tokens,
                        "temperature": 0.7
                    }
                }

                start_time = asyncio.get_event_loop().time()
                async with session.post(self.ollama_url, json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        processing_time = asyncio.get_event_loop().time() - start_time
                        response_text = result.get("response", "")

                        # Validate and reload if needed for code generation tasks
                        if validate_code and self.decision_engine:
                            final_response, final_model, validation = await self.decision_engine.validate_and_reload_if_needed(
                                response_text,
                                prompt,
                                model,
                                "code" if self._is_code_prompt(prompt) else "general"
                            )

                            if validation.is_gibberish or validation.requires_reload:
                                logger.info(f"üîÑ Reloaded model from {model} to {final_model} due to quality issues")

                            return {
                                "success": True,
                                "response": final_response,
                                "processing_time": processing_time,
                                "model": final_model,
                                "original_model": model if final_model != model else None,
                                "validation_score": validation.quality_score if validation else None,
                                "was_reloaded": final_model != model
                            }

                        return {
                            "success": True,
                            "response": response_text,
                            "processing_time": processing_time,
                            "model": model
                        }
                    else:
                        return {"success": False, "error": f"HTTP {response.status}"}

        except Exception as e:
            logger.error(f"Model query failed for {model}: {e}")
            return {"success": False, "error": str(e)}

    def _is_code_prompt(self, prompt: str) -> bool:
        """Detect if the prompt is asking for code generation"""
        code_indicators = [
            "write code", "generate code", "create a function", "implement",
            "write a script", "create a class", "code for", "program",
            "python", "javascript", "sql", "bash", "typescript", "fix this",
            "debug", "error in", "syntax"
        ]
        prompt_lower = prompt.lower()
        return any(indicator in prompt_lower for indicator in code_indicators)
    
    async def progressive_escalation(self, query: str, context: Dict) -> Dict:
        """Implement progressive model escalation with ML-driven decision engine"""
        escalation_path = []
        start_time = time.time()

        # üß† START THINKING - Begin neural visualization
        thought_id = await echo_brain.start_thinking("query_processing", query)

        # üß† PROCESS INPUT
        await echo_brain.think_about_input(thought_id, query)

        # Use ML decision engine for intelligent model selection
        decision = await self.decision_engine.decide_model(query, context)

        # üß† ANALYZE COMPLEXITY
        await echo_brain.analyze_complexity(thought_id, decision["complexity_score"] / 100.0)

        model = decision["model"]
        escalation_path.append(f"{decision['tier']}:{model}")

        # üß† DECISION: ML-DRIVEN MODEL SELECTION
        await echo_brain.make_decision(
            thought_id,
            "ml_selection",
            f"Selected {model} based on complexity {decision['complexity_score']:.1f}"
        )

        # Check if we need to use API
        if decision.get("use_api"):
            # Use DeepSeek API for extreme complexity
            result = await self._query_deepseek_api(query)
            escalation_path.append("api_fallback")
        else:
            # üß† GENERATE RESPONSE
            await echo_brain.generate_response(thought_id, f"{decision['tier']} response")

            # Attempt query with selected model
            result = await self.query_model(model, query)
        
        if result["success"]:
            # üß† SUCCESS - Complete thinking
            await echo_brain.finish_thinking(thought_id)

            # Record performance for learning
            elapsed = time.time() - start_time
            token_count = len(result.get("response", "").split())

            return {
                **result,
                "intelligence_level": decision["tier"],
                "escalation_path": escalation_path,
                "thought_id": thought_id,
                "brain_activity": echo_brain.get_brain_state(),
                "complexity_score": decision["complexity_score"],
                "decision_reason": decision["reason"]
            }
        else:
            # üß† ESCALATION NEEDED
            await echo_brain.emotional_response(thought_id, "concern", "Initial model failed")
            
            # Try API fallback for failed queries
            if decision["tier"] != "cloud":
                logger.info(f"Escalating to DeepSeek API after {model} failure")
                escalation_path.append("api_fallback")

                # üß† ESCALATION DECISION
                await echo_brain.make_decision(thought_id, "api_escalation", "Escalating to cloud API")

                fallback_result = await self._query_deepseek_api(query)
                await echo_brain.finish_thinking(thought_id)

                return {
                    **fallback_result,
                    "intelligence_level": "cloud",
                    "escalation_path": escalation_path,
                    "thought_id": thought_id,
                    "brain_activity": echo_brain.get_brain_state()
                }
            else:
                await echo_brain.finish_thinking(thought_id)
                return {
                    **result,
                    "thought_id": thought_id,
                    "brain_activity": echo_brain.get_brain_state()
                }

    async def _query_deepseek_api(self, query: str) -> Dict:
        """Query DeepSeek API for extreme complexity"""
        try:
            # Use existing DeepSeek service on port 8306
            async with aiohttp.ClientSession() as session:
                payload = {
                    "prompt": query,
                    "model": "deepseek-coder",
                    "max_tokens": 2048
                }

                async with session.post(
                    "http://localhost:8306/api/deepseek/chat",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=60)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return {
                            "success": True,
                            "response": result.get("response", ""),
                            "processing_time": result.get("processing_time", 0),
                            "model": "deepseek-api"
                        }
                    else:
                        return {"success": False, "error": f"API returned {response.status}"}

        except Exception as e:
            logger.error(f"DeepSeek API query failed: {e}")
            return {"success": False, "error": str(e)}

class ConversationManager:
    """Manages conversation context and intent recognition"""
    
    def __init__(self):
        self.conversations = {}  # In-memory for now, can move to Redis/DB later
        self.intent_patterns = {
            "service_testing": [
                r"test\s+(\w+)",
                r"run.*test.*on\s+(\w+)",
                r"check\s+(\w+).*working",
                r"verify\s+(\w+).*status",
                r"test.*(comfyui|anime|dashboard|auth|echo|deepseek|kb|voice)"
            ],
            "service_debugging": [
                r"debug\s+(\w+)",
                r"troubleshoot\s+(\w+)",
                r"diagnose\s+(\w+).*problem",
                r"analyze\s+(\w+).*issue",
                r"debug.*(comfyui|anime|dashboard|auth|echo|deepseek|kb|voice)"
            ],
            "service_monitoring": [
                r"status\s+(\w+)",
                r"health\s+(\w+)",
                r"check\s+(\w+).*health",
                r"monitor\s+(\w+)",
                r"get.*stats|statistics"
            ],
            "agent_delegation": [
                r"delegate.*to\s+(\w+)",
                r"send.*to\s+(architect|security|guardian|weights|balances)",
                r"assign.*task.*to",
                r"route.*to.*agent",
                r"have.*(architect|security|guardian).*handle",
                r"delegate.*complex.*task"
            ],
            "inter_service_communication": [
                r"communicate.*with\s+(\w+)",
                r"send.*message.*to\s+(\w+)",
                r"connect.*to\s+(\w+).*service",
                r"talk.*to\s+(\w+)",
                r"interface.*with\s+(\w+)"
            ],
                        "code_modification": [
                r"write.*script.*at",
                r"create.*file.*at", 
                r"write.*file",
                r"save.*content.*to",
                r"write.*to.*file",
                r"modify|change|update|edit|fix.*code|file",
                r"add.*function|method|class",
                r"refactor|rewrite"
            ],
            "debugging": [
                r"error|bug|issue|problem|fail|crash",
                r"debug|troubleshoot|diagnose",
                r"not working|broken"
            ],
            "architecture": [
                r"design|architecture|structure|organize",
                r"system|framework|pattern",
                r"how.*build|implement.*system"
            ],
            "ci_cd": [
                r"deploy|deployment|ci/cd|pipeline",
                r"build|test.*automation",
                r"git|version control|workflow"
            ],
            "explanation": [
                r"what.*is|how.*does|explain|understand",
                r"learn|tutorial|guide",
                r"difference between"
            ]
        }
        
        self.clarifying_questions = {
            "code_modification": [
                "Which specific files need to be modified?",
                "What exact functionality should be added or changed?",
                "Are there any constraints or requirements I should know about?",
                "Should this integrate with existing code patterns?"
            ],
            "debugging": [
                "What specific error message are you seeing?",
                "When does this error occur (what triggers it)?",
                "What was the last working state?",
                "Have you tried any solutions already?"
            ],
            "architecture": [
                "What's the main goal of this system?",
                "Are there performance or scalability requirements?",
                "Should this integrate with your existing Tower services?",
                "What's your timeline for implementation?"
            ],
            "ci_cd": [
                "What type of project are we deploying?",
                "Do you have existing CI/CD infrastructure?",
                "What environments need to be supported?",
                "Are there specific testing requirements?"
            ],
            "explanation": [
                "What's your current level of understanding with this topic?",
                "Are you looking for a high-level overview or technical details?",
                "Is this for a specific project or general learning?",
                "Do you prefer code examples or conceptual explanations?"
            ]
        }
    
    def classify_intent(self, query: str, conversation_history: List[Dict] = []) -> tuple[str, float, Dict]:
        """Classify user intent with confidence score and extracted parameters"""
        query_lower = query.lower()
        intent_params = {}
        
        # Check conversation context for intent continuation
        if conversation_history:
            last_intent = conversation_history[-1].get("intent")
            if last_intent and any(pattern in query_lower for pattern in ["yes", "no", "continue", "more"]):
                return last_intent, 0.9, {}
        
        # Pattern-based intent classification with parameter extraction
        intent_scores = {}
        for intent, patterns in self.intent_patterns.items():
            score = 0
            for pattern in patterns:
                match = re.search(pattern, query_lower)
                if match:
                    score += 0.8  # Higher confidence for direct matches
                    # Extract service names from patterns
                    if intent in ['service_testing', 'service_debugging', 'service_monitoring', 'inter_service_communication']:
                        # Try to extract service name from the match
                        groups = match.groups()
                        if groups:
                            intent_params['target_service'] = groups[0]
                        else:
                            # Look for known service names in the query
                            services = ['comfyui', 'anime', 'dashboard', 'auth', 'echo', 'kb', 'deepseek', 'voice']
                            for service in services:
                                if service in query_lower:
                                    intent_params['target_service'] = service
                                    break
                            # Also try to extract from the match groups for more complex patterns
                            if len(groups) > 0 and groups[0] in ['comfyui', 'anime', 'dashboard', 'auth', 'echo', 'kb', 'deepseek', 'voice']:
                                intent_params['target_service'] = groups[0]
                    
                    # Extract agent names for delegation
                    if intent == 'agent_delegation':
                        groups = match.groups()
                        if groups:
                            intent_params['target_agent'] = groups[0]
                        else:
                            # Look for known agent names in the query
                            agents = ['architect', 'security', 'guardian', 'weights', 'balances', 'vision']
                            for agent in agents:
                                if agent in query_lower:
                                    intent_params['target_agent'] = agent
                                    break
            
            if score > 0:
                intent_scores[intent] = min(score, 1.0)
        
        if not intent_scores:
            return "general", 0.5, {}
        
        best_intent = max(intent_scores.items(), key=lambda x: x[1])
        return best_intent[0], best_intent[1], intent_params
    
    def needs_clarification(self, intent: str, confidence: float, query: str) -> bool:
        """Determine if query needs clarification"""
        # Capability intents never need clarification - execute directly
        if intent in ['service_testing', 'service_debugging', 'service_monitoring', 'agent_delegation', 'inter_service_communication', 'code_modification']:
            return False
        
        # Low confidence always needs clarification
        if confidence < 0.3:  # Changed from 0.6 to only clarify on very low confidence
            return True
        
        # Check for vague queries even with good intent classification
        vague_indicators = [
            len(query.split()) < 5,  # Very short queries
            "help" in query.lower() and len(query.split()) < 8,
            query.count("?") == 0 and intent != "explanation",  # No questions but unclear intent
        ]
        
        return any(vague_indicators)
    
    def get_clarifying_questions(self, intent: str, query: str) -> List[str]:
        """Get relevant clarifying questions for intent"""
        questions = self.clarifying_questions.get(intent, [
            "Can you provide more details about what you're trying to accomplish?",
            "What specific aspects would you like me to focus on?",
            "Are there any constraints or preferences I should know about?"
        ])
        
        # Limit to 2-3 most relevant questions to avoid overwhelming
        return questions[:3]
    
    def update_conversation(self, conversation_id: str, user_query: str, 
                          intent: str, response: str, requires_clarification: bool):
        """Update conversation history"""
        if conversation_id not in self.conversations:
            self.conversations[conversation_id] = {
                "history": [],
                "created_at": datetime.now(),
                "last_intent": None
            }
        
        self.conversations[conversation_id]["history"].append({
            "user_query": user_query,
            "intent": intent,
            "response": response,
            "requires_clarification": requires_clarification,
            "timestamp": datetime.now()
        })
        
        self.conversations[conversation_id]["last_intent"] = intent
        
        # Keep conversation history manageable (last 10 interactions)
        if len(self.conversations[conversation_id]["history"]) > 10:
            self.conversations[conversation_id]["history"] = \
                self.conversations[conversation_id]["history"][-10:]
    
    def get_conversation_context(self, conversation_id: str) -> Dict:
        """Get conversation context for better processing"""
        if conversation_id not in self.conversations:
            return {}
        
        conv = self.conversations[conversation_id]
        return {
            "history": conv["history"],
            "last_intent": conv.get("last_intent"),
            "interaction_count": len(conv["history"])
        }

class EchoDatabase:
    """Unified database manager for Echo learning"""
    
    def __init__(self):
        # SECURITY FIX: Use environment variables for sensitive database credentials
        import os

        self.db_config = {
            "host": os.environ.get("DB_HOST", "localhost"),
            "database": os.environ.get("DB_NAME", "tower_consolidated"),
            "user": os.environ.get("DB_USER", "patrick")
        }

        # Note: No password required for local Tower database with user 'patrick'
    
    async def log_interaction(self, query: str, response: str, model_used: str, 
                            processing_time: float, escalation_path: List[str],
                            conversation_id: Optional[str] = None, user_id: str = "default",
                            intent: Optional[str] = None, confidence: float = 0.0,
                            requires_clarification: bool = False, 
                            clarifying_questions: Optional[List[str]] = None):
        """Log interaction for learning improvement"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO echo_unified_interactions 
                (query, response, model_used, processing_time, escalation_path, 
                 conversation_id, user_id, intent, confidence, requires_clarification, 
                 clarifying_questions)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (query, response, model_used, processing_time, 
                  json.dumps(escalation_path), conversation_id or "", user_id, intent or "", 
                  confidence, requires_clarification, json.dumps(clarifying_questions or [])))
                  
            conn.commit()
            cursor.close()
            conn.close()
            
        except Exception as e:
            logger.error(f"Database logging failed: {e}")
    
    async def create_tables_if_needed(self):
        """Create unified Echo tables"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS echo_unified_interactions (
                    id SERIAL PRIMARY KEY,
                    conversation_id VARCHAR(100),
                    user_id VARCHAR(100) DEFAULT 'default',
                    query TEXT NOT NULL,
                    response TEXT NOT NULL,
                    model_used VARCHAR(100) NOT NULL,
                    processing_time FLOAT NOT NULL,
                    escalation_path JSONB,
                    intent VARCHAR(50),
                    confidence FLOAT,
                    requires_clarification BOOLEAN DEFAULT FALSE,
                    clarifying_questions JSONB,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS echo_conversations (
                    id SERIAL PRIMARY KEY,
                    conversation_id VARCHAR(100) UNIQUE NOT NULL,
                    user_id VARCHAR(100) DEFAULT 'default',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_interaction TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    intent_history JSONB,
                    context JSONB
                )
            """)
            
            conn.commit()
            cursor.close()
            conn.close()
            logger.info("Echo unified database tables initialized")
            
        except Exception as e:
            logger.error(f"Database initialization failed: {e}")

# FastAPI Application
app = FastAPI(
    title="Echo Brain Unified Service",
    description="Consolidated Echo intelligence with dynamic 1B-70B parameter scaling and Board of Directors decision system",
    version="1.0.0"
)

# Mount static files for board dashboard
try:
    app.mount("/board", StaticFiles(directory="/opt/tower-echo-brain/frontend", html=True), name="board_dashboard")
    logger.info("üé® Board dashboard static files mounted at /board")
except Exception as e:
    logger.warning(f"Failed to mount board dashboard static files: {e}")

# Include Telegram router for general support
app.include_router(telegram_router)
logger.info("üì± Telegram general integration enabled")

# Include Veteran Guardian router for specialized veteran support
app.include_router(veteran_router)
logger.info("üéñÔ∏è Veteran Guardian Bot integration enabled")

# Include Agent Development router for autonomous agent creation
app.include_router(agent_dev_router)
logger.info("ü§ñ Agent Development System enabled")

# Import and initialize Anime Story Orchestrator
try:
    from anime_story_orchestrator import AnimeStoryOrchestrator
    anime_orchestrator = AnimeStoryOrchestrator()
    logger.info("üéå Anime Story Orchestrator (agenticPersona) enabled")
except Exception as e:
    logger.warning(f"Failed to initialize Anime Story Orchestrator: {e}")
    anime_orchestrator = None

# Capability handler function
async def handle_capability_intent(intent: str, params: Dict, request: QueryRequest, conversation_id: str, start_time: float) -> QueryResponse:
    """Handle capability intents by automatically using Echo's APIs"""
    try:
        if intent == "service_testing":
            target = params.get('target_service', 'echo')  # Default to self-test
            logger.info(f"üß™ AUTO-TESTING: Running test on {target}")
            
            # Execute test automatically
            test_result = await testing_framework.run_universal_test(target)
            
            if test_result['success']:
                response_text = f"‚úÖ Test completed for {target}!\n\nResults:\n{test_result['output']}"
                if test_result.get('error'):
                    response_text += f"\n‚ö†Ô∏è Warnings: {test_result['error']}"
            else:
                response_text = f"‚ùå Test failed for {target}\n\nError: {test_result.get('error', 'Unknown error')}\n\nOutput: {test_result['output']}"
            
            response_text += f"\n\n‚è±Ô∏è Processing time: {test_result['processing_time']:.2f}s"
            
        elif intent == "service_debugging":
            target = params.get('target_service', 'echo')
            logger.info(f"üîç AUTO-DEBUG: Running debug analysis on {target}")
            
            # Execute debug automatically  
            debug_result = await testing_framework.run_debug_analysis(target)
            
            if debug_result['success']:
                response_text = f"üîç Debug analysis completed for {target}!\n\nAnalysis:\n{debug_result['output']}"
                if debug_result.get('error'):
                    response_text += f"\n‚ö†Ô∏è Issues found: {debug_result['error']}"
            else:
                response_text = f"‚ùå Debug analysis failed for {target}\n\nError: {debug_result.get('error', 'Unknown error')}\n\nOutput: {debug_result['output']}"
            
            response_text += f"\n\n‚è±Ô∏è Processing time: {debug_result['processing_time']:.2f}s"
            
        elif intent == "service_monitoring":
            if 'stats' in request.query.lower() or 'statistics' in request.query.lower():
                logger.info(f"üìä AUTO-STATS: Getting Echo statistics")
                
                # Get Echo's own statistics
                try:
                    conn = psycopg2.connect(**database.db_config)
                    cursor = conn.cursor()
                    
                    cursor.execute("""
                        SELECT 
                            COUNT(*) as total_queries,
                            AVG(processing_time) as avg_processing_time,
                            model_used,
                            COUNT(*) as usage_count
                        FROM echo_unified_interactions 
                        GROUP BY model_used
                        ORDER BY usage_count DESC
                        LIMIT 10
                    """)
                    
                    stats = cursor.fetchall()
                    cursor.close()
                    conn.close()
                    
                    if stats:
                        response_text = "üìä Echo Brain Statistics\n\n"
                        total_queries = stats[0][0] if stats else 0
                        response_text += f"Total queries processed: {total_queries}\n\n"
                        response_text += "Model Usage:\n"
                        for row in stats:
                            model = row[2]
                            usage_count = row[3]
                            avg_time = float(row[1]) if row[1] else 0
                            response_text += f"‚Ä¢ {model}: {usage_count} uses (avg {avg_time:.2f}s)\n"
                    else:
                        response_text = "üìä No statistics available yet. Start using Echo to generate data!"
                        
                except Exception as e:
                    response_text = f"‚ùå Failed to retrieve statistics: {str(e)}"
            else:
                target = params.get('target_service', 'tower')
                logger.info(f"üìä AUTO-STATUS: Getting status for {target}")
                
                # Get service status
                status_result = await testing_framework.run_tower_command("status")
                
                if status_result['success']:
                    response_text = f"üìä Status report for Tower services:\n\n{status_result['output']}"
                else:
                    response_text = f"‚ùå Failed to get status: {status_result.get('error', 'Unknown error')}"
        
        elif intent == "agent_delegation":
            logger.info(f"üéØ DELEGATION: Routing task to orchestrator")
            
            # Extract task details from the query
            task_description = request.query
            task_type = "analysis"  # Default type
            
            # Determine task type from query content
            if any(word in request.query.lower() for word in ['security', 'audit', 'vulnerability']):
                task_type = "security"
            elif any(word in request.query.lower() for word in ['architect', 'design', 'planning']):
                task_type = "design"
            elif any(word in request.query.lower() for word in ['development', 'coding', 'implementation']):
                task_type = "development"
            elif any(word in request.query.lower() for word in ['review', 'quality', 'testing']):
                task_type = "review"
            elif any(word in request.query.lower() for word in ['deploy', 'deployment', 'infrastructure']):
                task_type = "deployment"
            elif any(word in request.query.lower() for word in ['monitor', 'monitoring', 'observability']):
                task_type = "monitoring"
            
            # Submit task to orchestrator
            delegation_result = await orchestrator.submit_task(
                task_type=task_type,
                description=task_description,
                requirements={"context": request.context},
                priority=7  # High priority for delegated tasks
            )
            
            if delegation_result['success']:
                # Get available agents for reporting
                agents_result = await orchestrator.get_available_agents()
                if agents_result['success']:
                    agent_count = len(agents_result['agents'])
                    online_agents = len([a for a in agents_result['agents'] if a.get('status') == 'online'])
                    response_text = f"üéØ Task delegated successfully!\n\n"
                    response_text += f"üìã Task ID: {delegation_result['task_id']}\n"
                    response_text += f"üè∑Ô∏è Task Type: {task_type}\n"
                    response_text += f"üìù Description: {task_description[:100]}...\n"
                    response_text += f"ü§ñ Available Agents: {online_agents}/{agent_count} online\n"
                    response_text += f"‚ö° Status: {delegation_result['status']}\n\n"
                    response_text += "The orchestrator will assign this task to the most suitable agent and execute it autonomously."
                else:
                    response_text = f"üéØ Task delegated (ID: {delegation_result['task_id']}) but couldn't get agent status."
            else:
                response_text = f"‚ùå Failed to delegate task: {delegation_result.get('error', 'Unknown error')}"
        
        elif intent == "inter_service_communication":
            service_name = params.get('target_service', 'dashboard')  # Default to dashboard
            logger.info(f"üí¨ COMMUNICATION: Establishing connection with {service_name}")
            
            # Communicate with the target service
            comm_result = await orchestrator.communicate_with_service(service_name, request.query)
            
            if comm_result['success']:
                response_text = f"üí¨ Communication established with {service_name}!\n\n"
                response_text += f"üì° Service: {comm_result['service']}\n"
                response_text += f"üìã Status: {comm_result['status']}\n"
                response_text += f"‚úÖ Message: {comm_result['message']}\n\n"
                response_text += f"The {service_name} service is responding and available for interaction."
            else:
                response_text = f"‚ùå Failed to communicate with {service_name}: {comm_result.get('error', 'Unknown error')}"
        
        elif intent == "code_modification":
            logger.info(f"üìù AUTO-CODE: Executing file operation")
            
            # Extract file path and content from query
            import re
            path_match = re.search(r"(?:at|to)\s+([^\s]+(?:\.py|\.sh|\.js|\.txt|\.json|\.yaml|\.md))", request.query)
            content_match = re.search(r"(?:with|containing)\s+(.+)$", request.query)
            
            if path_match:
                file_path = path_match.group(1)
                content = content_match.group(1) if content_match else "# Auto-generated content"
                
                try:
                    # Simple file write operation
                    import os
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    with open(file_path, "w") as f:
                        if "hello world" in content.lower():
                            f.write("print(\"Hello World!\")\n")
                        else:
                            f.write(content + "\n")
                    
                    response_text = f"‚úÖ File created successfully!\n\nPath: {file_path}\nContent: {content}\n\nFile is ready for use."
                except Exception as file_error:
                    response_text = f"‚ùå Failed to create file: {str(file_error)}"
            else:
                response_text = f"‚ùå Could not extract file path from query. Please specify a file path like \"/tmp/test.py\""
        
        else:
            response_text = f"ü§ñ I recognized a {intent} request but I'm not sure how to handle it yet. Let me learn from this!"
        
        # Create response
        processing_time = asyncio.get_event_loop().time() - start_time
        response = QueryResponse(
            response=response_text,
            model_used="echo_capability_handler",
            intelligence_level="autonomous",
            processing_time=processing_time,
            escalation_path=["autonomous_capability"],
            requires_clarification=False,
            clarifying_questions=[],
            conversation_id=conversation_id,
            intent=intent,
            confidence=0.95  # High confidence for capability execution
        )
        
        # Log the autonomous action
        await database.log_interaction(
            request.query, response_text, "echo_capability_handler",
            processing_time, ["autonomous_capability"],
            conversation_id, request.user_id, intent, 0.95,
            False, []
        )
        
        return response
        
    except Exception as e:
        logger.error(f"Capability handler error: {e}")
        error_response = f"‚ùå I tried to handle your {intent} request automatically, but encountered an error: {str(e)}"
        
        processing_time = asyncio.get_event_loop().time() - start_time
        return QueryResponse(
            response=error_response,
            model_used="echo_capability_handler", 
            intelligence_level="autonomous",
            processing_time=processing_time,
            escalation_path=["autonomous_capability_error"],
            requires_clarification=False,
            clarifying_questions=[],
            conversation_id=conversation_id,
            intent=intent,
            confidence=0.95
        )

# Global instances
# Initialize database first (needed by router's decision engine)
database = EchoDatabase()
router = EchoIntelligenceRouter()
conversation_manager = ConversationManager()
testing_framework = TowerTestingFramework()
shell_executor = SafeShellExecutor()
orchestrator = TowerOrchestrator()

# Board of Directors system instances
try:
    # Initialize Board system components
    request_logger = RequestLogger(database.db_config)
    feedback_processor = FeedbackProcessor(database.db_config)
    user_preferences = UserPreferences(database.db_config)
    knowledge_manager = create_simple_knowledge_manager(database.db_config)
    sandbox_executor = create_strict_sandbox()

    # Initialize director registry
    service_registry = ServiceRegistry()

    # Create Board API
    board_api = create_board_api(request_logger, service_registry)

    # Set global board_registry for model manager
    board_registry = service_registry

    logger.info("üèõÔ∏è Board of Directors system initialized")

    # Mount Board API endpoints
    if board_api:
        app.mount("/api/board", board_api.get_app())
        logger.info("üèõÔ∏è Board API endpoints mounted at /api/board")

except Exception as e:
    logger.error(f"Failed to initialize Board system: {e}")
    # Fall back to None values for graceful degradation
    request_logger = None
    feedback_processor = None
    user_preferences = None
    knowledge_manager = None
    sandbox_executor = None
    service_registry = None
    board_registry = None
    board_api = None

@app.on_event("startup")
async def startup():
    """Initialize service on startup"""
    await database.create_tables_if_needed()

    # Initialize Board database schema if available
    if board_api:
        try:
            # Run database schema initialization
            schema_path = "/opt/tower-echo-brain/board_database_schema.sql"
            if os.path.exists(schema_path):
                conn = psycopg2.connect(**database.db_config)
                cursor = conn.cursor()

                with open(schema_path, 'r') as f:
                    schema_sql = f.read()

                # Execute schema in chunks (PostgreSQL may have issues with large scripts)
                statements = schema_sql.split(';')
                for statement in statements:
                    statement = statement.strip()
                    if statement and not statement.startswith('--'):
                        try:
                            cursor.execute(statement)
                        except Exception as e:
                            # Log but continue - some statements may already exist
                            if "already exists" not in str(e).lower():
                                logger.warning(f"Schema statement warning: {e}")

                conn.commit()
                cursor.close()
                conn.close()
                logger.info("üèõÔ∏è Board database schema initialized")
            else:
                logger.warning("Board database schema file not found")

        except Exception as e:
            logger.error(f"Failed to initialize board database schema: {e}")

    logger.info("üß† Echo Brain Unified Service - Started")
    logger.info("üìä Intelligence Levels: 1B ‚Üí 70B parameters")
    logger.info("üöÄ Dynamic escalation enabled")
    if board_api:
        logger.info("üèõÔ∏è Board of Directors system active")
        logger.info("üìä Board dashboard available at /board-dashboard")

@app.get("/api/echo/health")
async def health_check():
    """Health check endpoint"""
    board_status = "enabled" if board_api else "disabled"
    return {
        "status": "healthy",
        "service": "Echo Brain Unified",
        "intelligence_levels": list(router.model_hierarchy.keys()),
        "specialized_models": list(router.specialized_models.keys()),
        "max_parameters": "70B",
        "timestamp": datetime.now().isoformat(),
        "board_system": {
            "status": board_status,
            "decision_tracking": request_logger is not None,
            "user_preferences": user_preferences is not None,
            "knowledge_management": knowledge_manager is not None,
            "sandbox_execution": sandbox_executor is not None
        }
    }

@app.get("/board-dashboard", response_class=HTMLResponse)
async def board_dashboard():
    """Serve the Board Room dashboard"""
    try:
        dashboard_path = "/opt/tower-echo-brain/frontend/board-room-dashboard.html"
        with open(dashboard_path, 'r') as f:
            html_content = f.read()
        return HTMLResponse(content=html_content)
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Board dashboard not found")
    except Exception as e:
        logger.error(f"Failed to serve board dashboard: {e}")
        raise HTTPException(status_code=500, detail="Failed to load board dashboard")

@app.post("/api/echo/query", response_model=QueryResponse)

@app.post("/api/echo/chat")
async def chat_endpoint(request: dict):
    """REST-compliant chat endpoint"""
    query_text = request.get("message", request.get("query", ""))
    intel_level = request.get("model", "auto")

    if intel_level == "auto":
        q_lower = query_text.lower()
        q_len = len(query_text)
        if q_len < 20 or "hello" in q_lower or "hi" in q_lower:
            intel_level = "quick"
        elif "code" in q_lower or "algorithm" in q_lower:
            intel_level = "expert"
        elif q_len > 200:
            intel_level = "genius"
        else:
            intel_level = "standard"

    query_req = QueryRequest(
        query=query_text,
        context=request.get("context", {}),
        intelligence_level=intel_level,
        user_id=request.get("user_id", "default"),
        conversation_id=request.get("conversation_id")
    )

    return await process_query(query_req)

async def process_query(request: QueryRequest):
    """Main conversational query processing endpoint with intent recognition"""
    
    start_time = asyncio.get_event_loop().time()
    
    try:
        # Generate conversation ID if not provided
        conversation_id = request.conversation_id or str(uuid.uuid4())
        
        # Get conversation context
        conv_context = conversation_manager.get_conversation_context(conversation_id)
        
        # Classify intent and confidence with parameter extraction
        intent, confidence, intent_params = conversation_manager.classify_intent(
            request.query, 
            conv_context.get("history", [])
        )
        
        logger.info(f"Intent: {intent}, Confidence: {confidence:.2f}, Params: {intent_params}")
        
        # Handle capability intents directly - no clarification needed
        if intent in ['service_testing', 'service_debugging', 'service_monitoring', 'agent_delegation', 'inter_service_communication', 'code_modification']:
            return await handle_capability_intent(intent, intent_params, request, conversation_id, start_time)
        
        # Check if clarification is needed for other intents
        needs_clarification = conversation_manager.needs_clarification(
            intent, confidence, request.query
        )
        
        if needs_clarification and False:  # DISABLED - always process instead of clarifying
            # Return clarifying questions instead of processing
            clarifying_questions = conversation_manager.get_clarifying_questions(intent, request.query)

            # Just process the query with best effort instead of asking questions
            logger.info(f"Low confidence ({confidence:.2f}) but proceeding anyway")
            response_text = f"Processing your request about {intent}..."
            needs_clarification = False  # Override - just do it!
            
            response = QueryResponse(
                response=response_text,
                model_used="conversation_manager",
                intelligence_level="clarification",
                processing_time=asyncio.get_event_loop().time() - start_time,
                escalation_path=["clarification"],
                requires_clarification=True,
                clarifying_questions=clarifying_questions,
                conversation_id=conversation_id,
                intent=intent,
                confidence=confidence
            )
            
            # Update conversation history
            conversation_manager.update_conversation(
                conversation_id, request.query, intent, response_text, True
            )
            
            # Log interaction
            await database.log_interaction(
                request.query, response_text, "conversation_manager", 
                response.processing_time, ["clarification"],
                conversation_id, request.user_id, intent, confidence,
                True, clarifying_questions
            )
            
            return response
        
        else:
            # Process with full context for better results
            enhanced_context = {
                **request.context,
                "conversation_history": conv_context.get("history", []),
                "intent": intent,
                "confidence": confidence,
                "user_id": request.user_id
            }

            # Check if board evaluation is needed for high-risk or complex queries
            board_evaluation_needed = False
            if board_api and request_logger:
                # Evaluate if board input is needed based on:
                # 1. Query complexity (long queries, technical terms)
                # 2. Risk indicators (system changes, security implications)
                # 3. User preference for board oversight
                risk_indicators = ['delete', 'remove', 'modify', 'change', 'update', 'install', 'configure', 'admin', 'root', 'sudo']
                complexity_score = len(request.query.split()) / 50.0  # Normalize by word count
                risk_score = sum(1 for indicator in risk_indicators if indicator in request.query.lower()) / len(risk_indicators)

                # Check user preferences for board oversight threshold
                user_pref = None
                if user_preferences:
                    try:
                        user_profile = user_preferences.get_user_profile(request.user_id)
                        if user_profile:
                            automation_level = user_profile.automation_level
                            # Lower automation level means more board involvement
                            board_evaluation_needed = (complexity_score > 0.3 and risk_score > 0.1) or automation_level < 0.6
                    except Exception as e:
                        logger.warning(f"Failed to get user preferences: {e}")

                # Default criteria if no user preferences
                if not user_pref:
                    board_evaluation_needed = complexity_score > 0.4 or risk_score > 0.2

            if board_evaluation_needed:
                try:
                    logger.info(f"üèõÔ∏è Submitting query to Board of Directors for evaluation")

                    # Create board task through the API
                    import aiohttp
                    async with aiohttp.ClientSession() as session:
                        board_request = {
                            "task_description": request.query,
                            "user_id": request.user_id,
                            "priority": "high" if risk_score > 0.3 else "normal",
                            "context": enhanced_context
                        }

                        async with session.post(
                            "http://localhost:8309/api/board/task",
                            json=board_request,
                            timeout=aiohttp.ClientTimeout(total=30)
                        ) as board_response:
                            if board_response.status == 200:
                                board_result = await board_response.json()
                                task_id = board_result.get("task_id")

                                # Return immediate response indicating board evaluation in progress
                                return QueryResponse(
                                    response=f"üèõÔ∏è Your request is being evaluated by the Board of Directors for safety and quality assurance.\n\nTask ID: {task_id}\n\nThis ensures the highest standards for system operations. You can monitor the decision process at /board-dashboard or check back in a few moments.",
                                    model_used="board_of_directors",
                                    intelligence_level="board_evaluation",
                                    processing_time=asyncio.get_event_loop().time() - start_time,
                                    escalation_path=["board_evaluation"],
                                    conversation_id=conversation_id,
                                    intent=intent,
                                    confidence=confidence
                                )
                            else:
                                logger.error(f"Board API request failed: {board_response.status}")

                except Exception as e:
                    logger.error(f"Failed to submit to board: {e}")
                    # Continue with normal processing if board fails

            # Process query through intelligence router
            result = await router.progressive_escalation(request.query, enhanced_context)
            
            if not result["success"]:
                raise HTTPException(status_code=500, detail=result.get("error", "Processing failed"))
            
            # Create enhanced response
            # Assess response quality using real quality metrics
            quality_metric = quality_monitor.assess_response_quality(
                query=request.query,
                response=result["response"],
                model_used=result["model"],
                response_time=result["processing_time"],
                success=result["success"],
                error_details=result.get("error")
            )
            
            # Log the quality metric for learning
            quality_monitor.log_interaction(quality_metric, conversation_id)
            
            # Validate output format
            validation_results = quality_monitor.validate_output(
                request.query, result["response"], request.context.get("expected_format")
            )
            
            # Add quality information to response metadata
            quality_info = {
                "relevance_score": quality_metric.relevance_score,
                "completeness_score": quality_metric.completeness_score,
                "accuracy_score": quality_metric.accuracy_score,
                "overall_quality": quality_metric.overall_quality.name,
                "validation_passed": validation_results["overall_valid"],
                "token_count": quality_metric.token_count
            }
            response = QueryResponse(
                response=result["response"],
                model_used=result["model"],
                intelligence_level=result["intelligence_level"],
                processing_time=result["processing_time"],
                escalation_path=result["escalation_path"],
                requires_clarification=False,
                clarifying_questions=[],
                conversation_id=conversation_id,
                intent=intent,
                confidence=confidence
            )
            
            # Update conversation history
            conversation_manager.update_conversation(
                conversation_id, request.query, intent, result["response"], False
            )
            
            # Log interaction for learning
            await database.log_interaction(
                request.query, result["response"], result["model"],
                result["processing_time"], result["escalation_path"],
                conversation_id, request.user_id, intent, confidence,
                False, []
            )
            
            return response
        
    except Exception as e:
        logger.error(f"Query processing error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/brain")
async def get_brain_activity():
    """Get current brain visualization state"""
    return {
        "brain_visualization": echo_brain.get_brain_state(),
        "thought_history_count": len(echo_brain.thought_history),
        "active_neurons": len(echo_brain.active_neurons),
        "service": "Echo Brain Neural Visualization",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/echo/thoughts/{thought_id}")
async def get_thought_stream(thought_id: str):
    """Get detailed thought stream for a specific thought"""
    thought_stream = echo_brain.get_thought_stream(thought_id)
    if not thought_stream:
        raise HTTPException(status_code=404, detail="Thought not found")
    
    return {
        "thought_id": thought_id,
        "thought_stream": thought_stream,
        "neuron_count": len(thought_stream),
        "service": "Echo Brain Thought Visualization"
    }

@app.get("/api/echo/stats")
async def get_statistics():
    """Get Echo Brain usage statistics"""
    try:
        conn = psycopg2.connect(**database.db_config)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                COUNT(*) as total_queries,
                AVG(processing_time) as avg_processing_time,
                model_used,
                COUNT(*) as usage_count
            FROM echo_unified_interactions 
            GROUP BY model_used
            ORDER BY usage_count DESC
        """)
        
        stats = cursor.fetchall()
        cursor.close()
        conn.close()
        
        return {
            "statistics": [
                {
                    "model": row[2],
                    "usage_count": row[3],
                    "avg_processing_time": float(row[1]) if row[1] else 0
                }
                for row in stats
            ],
            "total_queries": stats[0][0] if stats else 0
        }
        
    except Exception as e:
        logger.error(f"Stats retrieval failed: {e}")
        return {"error": str(e)}

@app.get("/api/echo/conversation/{conversation_id}")
async def get_conversation(conversation_id: str):
    """Get conversation history and context"""
    try:
        context = conversation_manager.get_conversation_context(conversation_id)
        if not context:
            raise HTTPException(status_code=404, detail="Conversation not found")
        
        return {
            "conversation_id": conversation_id,
            "history": context["history"],
            "last_intent": context.get("last_intent"),
            "interaction_count": context.get("interaction_count", 0)
        }
    except Exception as e:
        logger.error(f"Failed to retrieve conversation: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/echo/execute")
async def execute_task(request: dict):
    """Execute a task based on conversational understanding - CI/CD integration point"""
    try:
        conversation_id = request.get("conversation_id")
        if not conversation_id:
            raise HTTPException(status_code=400, detail="conversation_id required")
        
        # Get conversation context to understand what user wants
        context = conversation_manager.get_conversation_context(conversation_id)
        if not context or not context.get("history"):
            raise HTTPException(status_code=400, detail="No conversation context found")
        
        # Get the latest intent and requirements from conversation
        latest_interaction = context["history"][-1]
        intent = latest_interaction.get("intent")
        
        execution_plan = {
            "conversation_id": conversation_id,
            "intent": intent,
            "status": "ready_for_execution",
            "steps": []
        }
        
        # Generate execution steps based on intent
        if intent == "code_modification":
            execution_plan["steps"] = [
                "Analyze existing code structure",
                "Identify files to modify",
                "Implement changes with proper error handling",
                "Run tests to verify functionality",
                "Commit changes with descriptive message"
            ]
        elif intent == "ci_cd":
            execution_plan["steps"] = [
                "Analyze project structure and requirements",
                "Set up CI/CD pipeline configuration",
                "Configure automated testing",
                "Set up deployment scripts",
                "Test pipeline execution"
            ]
        elif intent == "debugging":
            execution_plan["steps"] = [
                "Reproduce the error condition",
                "Analyze error logs and stack traces",
                "Identify root cause",
                "Implement fix with proper testing",
                "Verify fix resolves the issue"
            ]
        else:
            execution_plan["steps"] = [
                "Analyze requirements from conversation",
                "Create implementation plan", 
                "Execute step-by-step",
                "Validate results",
                "Provide feedback to user"
            ]
        
        return execution_plan
        
    except Exception as e:
        logger.error(f"Execution planning failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/conversations")
async def list_conversations(user_id: str = "default", limit: int = 10):
    """List recent conversations for a user"""
    try:
        # Get conversations from memory (in production, query database)
        user_conversations = []
        for conv_id, conv_data in conversation_manager.conversations.items():
            if conv_data.get("history"):
                # Check if any interaction has this user_id (simplified check)
                user_conversations.append({
                    "conversation_id": conv_id,
                    "created_at": conv_data["created_at"].isoformat(),
                    "last_intent": conv_data.get("last_intent"),
                    "interaction_count": len(conv_data["history"]),
                    "last_query": conv_data["history"][-1]["user_query"][:100] + "..." if conv_data["history"] else ""
                })
        
        # Sort by creation date and limit
        user_conversations.sort(key=lambda x: x["created_at"], reverse=True)
        return {"conversations": user_conversations[:limit]}
        
    except Exception as e:
        logger.error(f"Failed to list conversations: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/stream")
async def stream_brain_activity():
    """Stream real-time brain activity using Server-Sent Events"""
    
    async def event_generator():
        """Generate Server-Sent Events for brain activity"""
        while True:
            try:
                # Get current brain state
                brain_state = echo_brain.get_brain_state()
                
                # Format as SSE event
                event_data = json.dumps({
                    "timestamp": datetime.now().isoformat(),
                    "brain_state": brain_state,
                    "service": "Echo Brain Stream"
                })
                
                yield f"data: {event_data}\n\n"
                
                # Wait before next update
                await asyncio.sleep(0.5)  # 2 updates per second
                
            except Exception as e:
                logger.error(f"Streaming error: {e}")
                yield f"data: {json.dumps({'error': str(e)})}\n\n"
                break
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

@app.post("/api/echo/anime/trailer")
async def create_anime_trailer(request: dict):
    """Create an anime trailer using agenticPersona storytelling orchestration"""
    try:
        if not anime_orchestrator:
            raise HTTPException(status_code=503, detail="Anime Story Orchestrator not available")

        # Extract trailer parameters
        title = request.get("title", "Untitled")
        description = request.get("description", "")
        themes = request.get("themes", [])
        style = request.get("style", "modern_anime")

        # Use Creative Expert personality for trailer creation
        from echo_expert_personalities import ExpertOrchestrator
        expert_orchestrator = ExpertOrchestrator()
        creative_expert = expert_orchestrator.select_expert(f"Create anime trailer for {title}")

        # Generate trailer structure with Creative Expert
        creative_suggestions = creative_expert.suggest_creative_approach(
            f"anime trailer for {title}: {description}"
        )

        # Create characters if needed
        main_character = anime_orchestrator.create_character(
            name=request.get("protagonist", "Protagonist"),
            traits=request.get("protagonist_traits", ["determined", "mysterious"]),
            backstory=request.get("backstory", "A mysterious past drives them forward")
        )

        # Generate trailer scenes
        trailer_data = {
            "title": title,
            "description": description,
            "scenes": creative_suggestions.get("narrative_structure", []),
            "visual_themes": creative_suggestions.get("visual_themes", []),
            "emotional_arc": creative_suggestions.get("emotional_progression", []),
            "music_bpm": request.get("music_bpm", 128),
            "duration": request.get("duration", 20),
            "main_character": {
                "name": main_character.name,
                "traits": main_character.traits,
                "visual": main_character.visual_description
            }
        }

        # Save to anime production system
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8328/api/anime/projects",
                json={
                    "name": f"{title} - Trailer",
                    "description": description,
                    "type": "trailer",
                    "metadata": trailer_data
                }
            ) as resp:
                if resp.status == 200:
                    project_response = await resp.json()
                    trailer_data["project_id"] = project_response.get("id")

        return {
            "status": "success",
            "trailer": trailer_data,
            "expert_used": creative_expert.name,
            "message": f"Trailer for '{title}' created using agenticPersona orchestration"
        }

    except Exception as e:
        logger.error(f"Anime trailer creation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/echo/stream-query")
async def stream_query_processing(request: QueryRequest):
    """Process query with real-time streaming of thought process"""
    
    async def query_stream_generator():
        """Generate real-time streaming of query processing"""
        try:
            # Generate conversation ID if not provided
            conversation_id = request.conversation_id or str(uuid.uuid4())
            
            # Send initial event
            yield f"data: {json.dumps({'type': 'start', 'conversation_id': conversation_id, 'query': request.query})}\n\n"
            
            # Get conversation context
            conv_context = conversation_manager.get_conversation_context(conversation_id)
            
            # Classify intent and confidence
            intent, confidence, intent_params = conversation_manager.classify_intent(
                request.query, 
                conv_context.get("history", [])
            )
            
            yield f"data: {json.dumps({'type': 'intent', 'intent': intent, 'confidence': confidence})}\n\n"
            
            # Check if clarification is needed
            needs_clarification = conversation_manager.needs_clarification(
                intent, confidence, request.query
            )
            
            if needs_clarification:
                clarifying_questions = conversation_manager.get_clarifying_questions(intent, request.query)
                yield f"data: {json.dumps({'type': 'clarification', 'questions': clarifying_questions})}\n\n"
                
                response_text = "I want to make sure I understand exactly what you need. Let me ask a few questions:\n\n"
                for i, question in enumerate(clarifying_questions, 1):
                    response_text += f"{i}. {question}\n"
                
                yield f"data: {json.dumps({'type': 'response', 'response': response_text, 'requires_clarification': True})}\n\n"
                
            else:
                # Process with streaming brain activity
                enhanced_context = {
                    **request.context,
                    "conversation_history": conv_context.get("history", []),
                    "intent": intent,
                    "confidence": confidence,
                    "user_id": request.user_id
                }
                
                # Start thinking process
                thought_id = await echo_brain.start_thinking("stream_query_processing", request.query)
                yield f"data: {json.dumps({'type': 'thinking_start', 'thought_id': thought_id})}\n\n"
                
                # Process with visible brain activity
                result = await router.progressive_escalation(request.query, enhanced_context)
                
                # Stream brain activity during processing
                brain_state = echo_brain.get_brain_state()
                yield f"data: {json.dumps({'type': 'brain_activity', 'brain_state': brain_state})}\n\n"
                
                if result["success"]:
                    yield f"data: {json.dumps({'type': 'response', 'response': result['response'], 'model_used': result['model'], 'processing_time': result['processing_time']})}\n\n"
                else:
                    yield f"data: {json.dumps({'type': 'error', 'error': result.get('error', 'Processing failed')})}\n\n"
            
            yield f"data: {json.dumps({'type': 'complete'})}\n\n"
            
        except Exception as e:
            logger.error(f"Stream query error: {e}")
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
    
    return StreamingResponse(
        query_stream_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

# Voice Integration Models
class VoiceNotificationRequest(BaseModel):
    message: str
    character: Optional[str] = "echo_default"
    tone: Optional[str] = "helpful"
    priority: Optional[str] = "normal"

class VoiceStatusRequest(BaseModel):
    service_name: str
    status: str
    details: Optional[str] = ""

# Voice Integration Endpoints
@app.post("/api/echo/voice/notify")
async def voice_notify(request: VoiceNotificationRequest):
    """Send voice notification using unified voice service"""
    try:
        voice_payload = {
            "text": request.message,
            "character": request.character,
            "tone": request.tone
        }
        
        # Send to unified voice service
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://localhost:8316/synthesize",
                json=voice_payload,
                timeout=aiohttp.ClientTimeout(total=10)
            ) as response:
                if response.status == 200:
                    # Check content type - voice service returns audio/wav
                    content_type = response.headers.get('Content-Type', '')
                    if 'audio' in content_type:
                        # Voice service returned audio directly
                        return {
                            "success": True,
                            "message": "Voice notification sent",
                            "audio_content_type": content_type,
                            "character": request.character,
                            "processing_time": 0.5  # Estimated
                        }
                    else:
                        # Try to parse as JSON
                        try:
                            result = await response.json()
                            return {
                                "success": True,
                                "message": "Voice notification sent",
                                "audio_file": result.get("audio_file"),
                                "character": request.character,
                                "processing_time": result.get("processing_time", 0)
                            }
                        except:
                            return {
                                "success": True,
                                "message": "Voice notification sent",
                                "character": request.character,
                                "processing_time": 0.5
                            }
                else:
                    return {
                        "success": False,
                        "error": f"Voice service error: {response.status}"
                    }
                    
    except Exception as e:
        logger.error(f"Voice notification error: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/echo/voice/status")
async def voice_status_update(request: VoiceStatusRequest):
    """Send voice status update for service changes"""
    try:
        status_message = f"{request.service_name} is now {request.status}"
        if request.details:
            status_message += f". {request.details}"
        
        voice_payload = {
            "text": status_message,
            "character": "echo_default",
            "tone": "informative"
        }
        
        # Send to unified voice service
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://localhost:8316/synthesize",
                json=voice_payload,
                timeout=aiohttp.ClientTimeout(total=10)
            ) as response:
                if response.status == 200:
                    # Check content type - voice service returns audio/wav
                    content_type = response.headers.get('Content-Type', '')
                    if 'audio' in content_type:
                        # Voice service returned audio directly
                        return {
                            "success": True,
                            "message": "Status voice notification sent",
                            "service": request.service_name,
                            "status": request.status,
                            "audio_content_type": content_type
                        }
                    else:
                        # Try to parse as JSON
                        try:
                            result = await response.json()
                            return {
                                "success": True,
                                "message": "Status voice notification sent",
                                "service": request.service_name,
                                "status": request.status,
                                "audio_file": result.get("audio_file")
                            }
                        except:
                            return {
                                "success": True,
                                "message": "Status voice notification sent",
                                "service": request.service_name,
                                "status": request.status
                            }
                else:
                    return {
                        "success": False,
                        "error": f"Voice service error: {response.status}"
                    }
                    
    except Exception as e:
        logger.error(f"Voice status error: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/echo/voice/characters")
async def get_voice_characters():
    """Get available voice characters from unified voice service"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(
                "http://127.0.0.1:8331/api/characters",
                timeout=aiohttp.ClientTimeout(total=5)
            ) as response:
                if response.status == 200:
                    characters = await response.json()
                    return {
                        "success": True,
                        "characters": characters,
                        "voice_service_url": "http://127.0.0.1:8331"
                    }
                else:
                    return {
                        "success": False,
                        "error": f"Voice service error: {response.status}"
                    }
                    
    except Exception as e:
        logger.error(f"Voice characters error: {e}")
        return {
            "success": False,
            "error": str(e),
            "fallback_characters": ["echo_default", "tokyo_debt_desire", "sakura"]
        }

# New Testing Framework Endpoints
@app.post("/api/echo/test/{target}")
async def run_universal_test(target: str, request: TestRequest = None):
    """Run universal testing on any target service"""
    try:
        logger.info(f"Running universal test on target: {target}")
        
        # Use target from path, but allow override from request body
        actual_target = request.target if request and request.target else target
        
        # Run the test
        result = await testing_framework.run_universal_test(actual_target)
        
        # Add metadata
        result["service"] = "Echo Brain Testing Framework"
        result["timestamp"] = datetime.now().isoformat()
        result["requested_target"] = target
        result["actual_target"] = actual_target
        
        return result
        
    except Exception as e:
        logger.error(f"Universal test failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/echo/debug/{service}")
async def debug_service(service: str):
    """Debug a specific Tower service with comprehensive analysis"""
    try:
        logger.info(f"Running debug analysis on service: {service}")
        
        # Run debug analysis
        result = await testing_framework.run_debug_analysis(service)
        
        # Add metadata
        result["service"] = "Echo Brain Debug Tools"
        result["timestamp"] = datetime.now().isoformat()
        result["debug_target"] = service
        
        return result
        
    except Exception as e:
        logger.error(f"Debug analysis failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/tower/status")
async def get_tower_status():
    """Get comprehensive Tower services status"""
    try:
        logger.info("Getting Tower services status")
        
        # Run status command
        result = await testing_framework.run_tower_command("status")
        
        return {
            "success": result["success"],
            "command": result["command"],
            "output": result["output"],
            "error": result.get("error"),
            "processing_time": result["processing_time"],
            "service": "Echo Brain Tower Status",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Status check failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/tower/health")
async def get_tower_health():
    """Get health status of all Tower services"""
    try:
        logger.info("Getting Tower services health")
        
        # Run health command
        result = await testing_framework.run_tower_command("health")
        
        return {
            "success": result["success"],
            "command": result["command"],
            "output": result["output"],
            "error": result.get("error"),
            "processing_time": result["processing_time"],
            "service": "Echo Brain Tower Health",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/echo/tower/{command}")
async def run_tower_command(command: str, request: dict = None):
    """Run any Tower framework command"""
    try:
        logger.info(f"Running Tower command: {command}")
        
        # Extract arguments from request body if provided
        args = []
        if request and "args" in request:
            args = request["args"] if isinstance(request["args"], list) else [request["args"]]
        
        # Run the command
        result = await testing_framework.run_tower_command(command, args)
        
        # Add metadata
        result["service"] = "Echo Brain Tower Command"
        result["timestamp"] = datetime.now().isoformat()
        result["requested_command"] = command
        result["args"] = args
        
        return result
        
    except Exception as e:
        logger.error(f"Tower command failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/testing/capabilities")
async def get_testing_capabilities():
    """Get information about Echo's testing framework capabilities"""
    try:
        capabilities = {
            "framework_name": "Tower Testing Framework",
            "integrated_with": "Echo Brain Unified Service",
            "version": "1.0.0",
            "capabilities": {
                "universal_testing": {
                    "description": "Comprehensive testing suite for any Tower service or external system",
                    "endpoint": "/api/echo/test/{target}",
                    "supports": ["HTTP endpoints", "Network connectivity", "JSON responses", "Service health"]
                },
                "debug_analysis": {
                    "description": "Advanced debugging capabilities with system resource analysis",
                    "endpoint": "/api/echo/debug/{service}",
                    "supports": ["Network debugging", "HTTP analysis", "System resources", "Log analysis", "Database connectivity"]
                },
                "shell_execution": {
                    "description": "Safe shell command execution with security controls",
                    "endpoint": "/api/echo/execute",
                    "features": ["Safety checks", "Command filtering", "Timeout protection", "Output capture"]
                },
                "tower_commands": {
                    "description": "Direct access to Tower framework commands",
                    "endpoints": ["/api/echo/tower/status", "/api/echo/tower/health", "/api/echo/tower/{command}"],
                    "commands": ["status", "health", "monitor", "logs", "restart"]
                }
            },
            "services": {
                "dashboard": "8080",
                "anime": "8300",
                "agent-manager": "8301",
                "loan-search": "8302",
                "crypto-trader": "8303",
                "comfyui": "8188",
                "deepseek": "8306",
                "kb": "8307",
                "echo": "8309",
                "auth": "8088",
                "voice": "8316"
            },
            "safety_features": {
                "safe_mode": "Enabled by default",
                "command_filtering": "Blocks dangerous operations",
                "timeout_protection": "30s for commands, 60s for tests, 120s for debug",
                "audit_logging": "All commands logged to database"
            },
            "examples": {
                "test_echo": "POST /api/echo/test/echo",
                "debug_comfyui": "POST /api/echo/debug/comfyui",
                "execute_command": "POST /api/echo/execute {\"command\": \"ls -la\"}",
                "tower_status": "GET /api/echo/tower/status"
            },
            "service": "Echo Brain Testing Framework",
            "timestamp": datetime.now().isoformat()
        }
        
        return capabilities
        
    except Exception as e:
        logger.error(f"Failed to get testing capabilities: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Model Management Endpoints
@app.post("/api/echo/models/manage", response_model=ModelManagementResponse)
async def manage_model(
    request: ModelManagementRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user)
):
    """
    Manage Ollama models (pull, update, remove) with Board oversight
    Requires admin privileges for protected models
    """
    try:
        # Initialize model manager with board system
        model_manager = get_model_manager(board_registry, request_logger)

        # Add user context
        request.user_id = current_user.get("username", "admin")

        # Process request
        response = await model_manager.request_model_operation(request, background_tasks)

        logger.info(f"Model operation {request.operation} for {request.model_name} initiated by {request.user_id}")

        return response

    except Exception as e:
        logger.error(f"Model management failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/models/list", response_model=List[ModelInfo])
async def list_installed_models():
    """
    List all installed Ollama models with metadata
    """
    try:
        model_manager = get_model_manager(board_registry, request_logger)
        models = await model_manager.get_installed_models()
        return models

    except Exception as e:
        logger.error(f"Failed to list models: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/echo/models/pull/{model_name}")
async def pull_model_quick(
    model_name: str,
    tag: str = "latest",
    reason: str = "Quick model pull",
    background_tasks: BackgroundTasks = None,
    current_user: dict = Depends(get_current_user)
):
    """
    Quick endpoint to pull a specific model
    """
    request = ModelManagementRequest(
        operation=ModelOperation.PULL,
        model_name=model_name,
        tag=tag,
        reason=reason,
        user_id=current_user.get("username", "admin")
    )

    model_manager = get_model_manager(board_registry, request_logger)
    response = await model_manager.request_model_operation(request, background_tasks)

    return response

@app.delete("/api/echo/models/{model_name}")
async def remove_model(
    model_name: str,
    tag: str = "latest",
    reason: str = "Model removal requested",
    background_tasks: BackgroundTasks = None,
    current_user: dict = Depends(get_current_user)
):
    """
    Remove a specific model (requires approval for protected models)
    """
    request = ModelManagementRequest(
        operation=ModelOperation.REMOVE,
        model_name=model_name,
        tag=tag,
        reason=reason,
        user_id=current_user.get("username", "admin"),
        force=False
    )

    model_manager = get_model_manager(board_registry, request_logger)
    response = await model_manager.request_model_operation(request, background_tasks)

    return response

@app.get("/api/echo/models/status/{request_id}")
async def get_operation_status(request_id: str):
    """
    Check status of a model operation request
    """
    try:
        # Check with decision tracker
        decision = request_logger.get_decision_status(request_id)

        if decision:
            return {
                "request_id": request_id,
                "status": decision.status.value,
                "consensus_score": decision.consensus_score,
                "confidence": decision.confidence_score,
                "message": decision.final_recommendation
            }
        else:
            raise HTTPException(status_code=404, detail="Request not found")

    except Exception as e:
        logger.error(f"Failed to get operation status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Quality Monitoring Endpoints

@app.get("/api/echo/quality/metrics")
async def get_quality_metrics(hours: int = 24, current_user: dict = Depends(get_current_user)):
    """Get quality metrics for the specified time period"""
    try:
        metrics = quality_monitor.get_performance_metrics(hours)
        return {
            "status": "success",
            "data": metrics,
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"Failed to get quality metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/quality/failures")
async def get_failure_patterns(limit: int = 10, current_user: dict = Depends(get_current_user)):
    """Get most common failure patterns"""
    try:
        patterns = quality_monitor.get_failure_patterns(limit)
        return {
            "status": "success",
            "data": patterns,
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"Failed to get failure patterns: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/echo/quality/snapshot")
async def take_performance_snapshot(current_user: dict = Depends(get_current_user)):
    """Take a performance snapshot for trending analysis"""
    try:
        quality_monitor.take_performance_snapshot()
        return {
            "status": "success",
            "message": "Performance snapshot taken",
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"Failed to take performance snapshot: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/echo/quality/validate")
async def validate_response_format(
    query: str,
    response: str,
    expected_format: Optional[str] = None,
    current_user: dict = Depends(get_current_user)
):
    """Validate response format and quality"""
    try:
        validation_results = quality_monitor.validate_output(query, response, expected_format)
        return {
            "status": "success",
            "validation": validation_results,
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"Failed to validate response: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.on_event("shutdown")
async def shutdown():
    """Cleanup on service shutdown"""
    try:
        # Cleanup Board system resources
        if sandbox_executor:
            sandbox_executor.cleanup()
            logger.info("üèõÔ∏è Board sandbox resources cleaned up")

        if knowledge_manager:
            knowledge_manager.cleanup()
            logger.info("üèõÔ∏è Board knowledge manager cleaned up")

        logger.info("üß† Echo Brain Unified Service - Shutdown complete")

    except Exception as e:
        logger.error(f"Error during shutdown: {e}")

if __name__ == "__main__":
    logger.info("üöÄ Starting Echo Brain Unified Service")
    logger.info("üîó Consolidating 5 fragmented Echo services")
    logger.info("üß† Dynamic intelligence scaling: 1B ‚Üí 70B parameters")
    logger.info("üîß Tower Testing Framework: INTEGRATED")
    logger.info("üõ°Ô∏è Safe shell execution: ENABLED")
    logger.info("üìä Universal testing capabilities: READY")
    logger.info("üèõÔ∏è Board of Directors system: READY")
    logger.info("üìä Quality Monitoring System: ENABLED")
    logger.info("üéØ Real-time Response Quality Assessment: ACTIVE")
    logger.info("üìà Performance Metrics & Failure Learning: READY")
    logger.info("‚úÖ Output Validation & Error Analysis: OPERATIONAL")
    logger.info("‚öñÔ∏è Transparent AI decision tracking: ENABLED")

    uvicorn.run(
        __name__ + ":app",
        host="0.0.0.0",
        port=8309,
        reload=False,
        workers=1
    )
# Import the blaster generator
import sys
sys.path.append('/opt/tower-echo-brain/modules')
from blaster_generator import BlasterGenerator

# Add to Echo's query processing
async def handle_3d_generation(query: str) -> str:
    """Handle 3D model generation requests"""
    
    if "turbosquid.com" in query or "printables.com" in query or "3d model" in query.lower():
        # Extract URL from query
        import re
        url_match = re.search(r'https?://[^\s]+', query)
        
        if url_match:
            url = url_match.group(0)
            result = BlasterGenerator.generate_from_url(url)
            
            if result["status"] == "success":
                return f"""‚úÖ Generated 3D model successfully!
                
File: {result['file']}
Type: {result['type']}
Vertices: {result['vertices']}

You can:
1. View at: http://192.168.50.135:8500
2. Download: wget http://192.168.50.135/downloads/{os.path.basename(result['file'])}
3. Load in 3D viewer on Tower"""
            else:
                return "‚ùå Failed to generate 3D model"
    
    return None

# Patch the existing query handler
_original_process_query = process_query

async def enhanced_process_query(query: str, conversation_id: str = None, **kwargs):
    """Enhanced query processor with 3D generation"""
    
    # Check if this is a 3D generation request
    result = await handle_3d_generation(query)
    if result:
        return {"response": result}
    
    # Fall back to original processing
    return await _original_process_query(query, conversation_id, **kwargs)

process_query = enhanced_process_query
