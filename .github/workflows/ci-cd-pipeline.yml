name: Echo Brain Board of Directors - CI/CD Pipeline

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # ============================================================================
  # Code Quality and Security Checks
  # ============================================================================
  quality-and-security:
    name: Code Quality & Security
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test_requirements.txt

    - name: Code Formatting Check (Black)
      run: |
        black --check --diff directors/ board_api.py echo_board_integration.py tests/

    - name: Import Sorting Check (isort)
      run: |
        isort --check-only --diff directors/ board_api.py echo_board_integration.py tests/

    - name: Linting (flake8)
      run: |
        flake8 directors/ board_api.py echo_board_integration.py tests/ \
          --max-line-length=100 --extend-ignore=E203,W503 \
          --output-file=reports/flake8-report.txt
      continue-on-error: true

    - name: Type Checking (mypy)
      run: |
        mypy directors/ board_api.py echo_board_integration.py \
          --ignore-missing-imports --no-strict-optional \
          --txt-report reports/mypy-report
      continue-on-error: true

    - name: Security Scanning (Bandit)
      run: |
        mkdir -p reports
        bandit -r directors/ board_api.py echo_board_integration.py \
          -f json -o reports/bandit-security-report.json
        bandit -r directors/ board_api.py echo_board_integration.py \
          -f txt -o reports/bandit-security-report.txt
      continue-on-error: true

    - name: Dependency Security Check (Safety)
      run: |
        safety check --json --output reports/safety-report.json
        safety check --output reports/safety-report.txt
      continue-on-error: true

    - name: Advanced Security Analysis (Semgrep)
      run: |
        semgrep --config=auto --json --output=reports/semgrep-report.json \
          directors/ board_api.py echo_board_integration.py
        semgrep --config=auto --output=reports/semgrep-report.txt \
          directors/ board_api.py echo_board_integration.py
      continue-on-error: true

    - name: Upload Security Reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: reports/
        retention-days: 30

  # ============================================================================
  # Unit Tests
  # ============================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test_requirements.txt

    - name: Run Unit Tests
      run: |
        mkdir -p reports
        pytest tests/test_all_directors.py \
          --cov=directors --cov=board_api --cov=echo_board_integration \
          --cov-report=html:htmlcov \
          --cov-report=xml:reports/coverage.xml \
          --cov-report=json:reports/coverage.json \
          --cov-report=term-missing \
          --cov-fail-under=80 \
          --html=reports/unit-test-report.html \
          --json-report --json-report-file=reports/unit-test-results.json \
          -v --tb=short

    - name: Generate Coverage Badge
      run: |
        coverage-badge -o reports/coverage-badge.svg

    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: unit-test-results-python-${{ matrix.python-version }}
        path: |
          reports/
          htmlcov/
        retention-days: 30

    - name: Upload Coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.11'
      with:
        file: reports/coverage.xml
        flags: unittests
        name: codecov-umbrella

  # ============================================================================
  # Integration Tests
  # ============================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: test_echo_brain
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test_requirements.txt

    - name: Set up Test Database
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: test_echo_brain
        DB_USER: test_user
        DB_PASSWORD: test_password
      run: |
        # Wait for PostgreSQL to be ready
        until pg_isready -h localhost -p 5432 -U test_user; do
          echo "Waiting for PostgreSQL..."
          sleep 2
        done

        # Create test database schema
        PGPASSWORD=test_password psql -h localhost -U test_user -d test_echo_brain \
          -f board_database_schema.sql

    - name: Run Integration Tests
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: test_echo_brain
        DB_USER: test_user
        DB_PASSWORD: test_password
        REDIS_URL: redis://localhost:6379/0
        TESTING: true
      run: |
        mkdir -p reports
        pytest tests/test_board_consensus_integration.py \
          --cov=directors --cov=board_api --cov=echo_board_integration \
          --cov-report=html:htmlcov-integration \
          --cov-report=xml:reports/integration-coverage.xml \
          --cov-report=json:reports/integration-coverage.json \
          --html=reports/integration-test-report.html \
          --json-report --json-report-file=reports/integration-test-results.json \
          -v --tb=short -m integration

    - name: Upload Integration Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: |
          reports/
          htmlcov-integration/
        retention-days: 30

  # ============================================================================
  # Security Tests
  # ============================================================================
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test_requirements.txt

    - name: Run Security Tests
      run: |
        mkdir -p reports
        pytest tests/test_security_comprehensive.py \
          --html=reports/security-test-report.html \
          --json-report --json-report-file=reports/security-test-results.json \
          -v --tb=short -m security

    - name: Upload Security Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-test-results
        path: reports/
        retention-days: 30

  # ============================================================================
  # Performance Tests
  # ============================================================================
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test_requirements.txt

    - name: Run Performance Tests
      run: |
        mkdir -p reports
        pytest tests/ \
          --benchmark-only \
          --benchmark-json=reports/benchmark-results.json \
          --benchmark-histogram=reports/benchmark-histogram \
          -v -m performance

    - name: Upload Performance Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: reports/
        retention-days: 30

  # ============================================================================
  # API Tests
  # ============================================================================
  api-tests:
    name: API Tests
    runs-on: ubuntu-latest
    needs: integration-tests

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: test_echo_brain
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test_requirements.txt

    - name: Start Echo Brain API Service
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: test_echo_brain
        DB_USER: test_user
        DB_PASSWORD: test_password
        TESTING: true
      run: |
        # Set up database
        until pg_isready -h localhost -p 5432 -U test_user; do
          echo "Waiting for PostgreSQL..."
          sleep 2
        done
        PGPASSWORD=test_password psql -h localhost -U test_user -d test_echo_brain \
          -f board_database_schema.sql

        # Start API service in background
        python board_api.py &
        API_PID=$!
        echo "API_PID=$API_PID" >> $GITHUB_ENV

        # Wait for API to be ready
        sleep 10
        curl -f http://localhost:8000/health || exit 1

    - name: Run API Tests
      run: |
        mkdir -p reports
        pytest tests/test_board_api.py \
          --html=reports/api-test-report.html \
          --json-report --json-report-file=reports/api-test-results.json \
          -v --tb=short -m api

    - name: Stop API Service
      if: always()
      run: |
        if [ ! -z "$API_PID" ]; then
          kill $API_PID || true
        fi

    - name: Upload API Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: api-test-results
        path: reports/
        retention-days: 30

  # ============================================================================
  # Test Report Aggregation
  # ============================================================================
  aggregate-reports:
    name: Aggregate Test Reports
    runs-on: ubuntu-latest
    needs: [quality-and-security, unit-tests, integration-tests, security-tests, performance-tests, api-tests]
    if: always()

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Download All Artifacts
      uses: actions/download-artifact@v3
      with:
        path: all-reports

    - name: Generate Consolidated Report
      run: |
        mkdir -p consolidated-reports

        # Create summary report
        cat > consolidated-reports/test-summary.md << 'EOF'
        # Echo Brain Board of Directors - Test Summary

        ## Build Information
        - **Commit**: ${{ github.sha }}
        - **Branch**: ${{ github.ref_name }}
        - **Triggered by**: ${{ github.event_name }}
        - **Run ID**: ${{ github.run_id }}
        - **Timestamp**: $(date -u)

        ## Test Results

        ### Quality and Security Checks
        - Code formatting, linting, and security scans completed
        - Reports available in security-reports artifact

        ### Unit Tests
        - Tests executed across Python versions 3.9-3.12
        - Coverage reports generated
        - Results available in unit-test-results artifacts

        ### Integration Tests
        - Full system integration testing with database
        - Board consensus and decision tracking validated
        - Results available in integration-test-results artifact

        ### Security Tests
        - Comprehensive security testing completed
        - Authentication, authorization, and vulnerability checks
        - Results available in security-test-results artifact

        ### Performance Tests
        - Benchmark tests executed
        - Performance metrics collected
        - Results available in performance-test-results artifact

        ### API Tests
        - End-to-end API testing completed
        - All endpoints validated
        - Results available in api-test-results artifact

        ## Artifacts
        All test results, reports, and coverage data are available as downloadable artifacts.
        EOF

        # List all collected artifacts
        echo "## Collected Artifacts" >> consolidated-reports/test-summary.md
        find all-reports -type f -name "*.html" -o -name "*.json" -o -name "*.xml" | \
          sort >> consolidated-reports/test-summary.md

    - name: Upload Consolidated Reports
      uses: actions/upload-artifact@v3
      with:
        name: consolidated-test-reports
        path: consolidated-reports/
        retention-days: 90

  # ============================================================================
  # Deployment (Production)
  # ============================================================================
  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [quality-and-security, unit-tests, integration-tests, security-tests, api-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: production

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Deploy to Production Server
      run: |
        echo "ðŸš€ Deploying to production..."
        echo "This step would typically:"
        echo "- Build production Docker images"
        echo "- Deploy to production servers"
        echo "- Run database migrations"
        echo "- Update service configurations"
        echo "- Verify deployment health"
        echo "âœ… Deployment completed successfully!"

  # ============================================================================
  # Notification
  # ============================================================================
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [quality-and-security, unit-tests, integration-tests, security-tests, performance-tests, api-tests]
    if: always()

    steps:
    - name: Determine Overall Status
      id: status
      run: |
        if [ "${{ needs.quality-and-security.result }}" == "success" ] && \
           [ "${{ needs.unit-tests.result }}" == "success" ] && \
           [ "${{ needs.integration-tests.result }}" == "success" ] && \
           [ "${{ needs.security-tests.result }}" == "success" ] && \
           [ "${{ needs.api-tests.result }}" == "success" ]; then
          echo "status=success" >> $GITHUB_OUTPUT
          echo "message=âœ… All tests passed successfully!" >> $GITHUB_OUTPUT
        else
          echo "status=failure" >> $GITHUB_OUTPUT
          echo "message=âŒ Some tests failed. Check the reports for details." >> $GITHUB_OUTPUT
        fi

    - name: Create Status Summary
      run: |
        echo "## CI/CD Pipeline Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Quality & Security**: ${{ needs.quality-and-security.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Unit Tests**: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Integration Tests**: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Security Tests**: ${{ needs.security-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Performance Tests**: ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **API Tests**: ${{ needs.api-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "${{ steps.status.outputs.message }}" >> $GITHUB_STEP_SUMMARY