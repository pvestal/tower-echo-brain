#!/usr/bin/env python3
"""
WORKING Echo Brain Service - ACTUALLY generates images through ComfyUI
Requirements:
1. Detect creative/anime/video keywords
2. Track story state across multiple calls
3. When story has character + setting, ACTUALLY call ComfyUI to generate image
4. Verify image creation in /home/patrick/ComfyUI/output/
5. Return actual image path in response
"""

import json
import re
import time
import uuid
import os
import asyncio
import websocket
import requests
import sqlite3
from datetime import datetime, timedelta
from fastapi import FastAPI, HTTPException, Path
from fastapi.responses import JSONResponse
from pydantic import BaseModel
# AgenticPersona Voice Integration
import aiohttp
from enum import Enum
from echo_voice_agentic_integration import (
    AgenticPersonaVoiceManager, VoiceCharacter, agentic_voice_manager,
    handle_voice_request, enhance_chat_with_voice
)

from typing import Dict, List, Optional, Any
import uvicorn

app = FastAPI()

# Story state storage (in-memory for now)
story_states: Dict[str, Dict] = {}
# Database initialization
DB_PATH = "/opt/tower-echo-brain/data/user_stats.db"

def init_database():
    """Initialize SQLite database for user statistics"""
    import os
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Create user_stats table
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS user_stats (
            user_id TEXT PRIMARY KEY,
            total_generations INTEGER DEFAULT 0,
            successful_generations INTEGER DEFAULT 0,
            failed_generations INTEGER DEFAULT 0,
            total_errors INTEGER DEFAULT 0,
            last_generation_time TEXT,
            first_seen TEXT,
            last_active TEXT,
            total_tokens_used INTEGER DEFAULT 0
        )
    """)
    
    # Create generation_log table for detailed tracking
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS generation_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            session_id TEXT,
            timestamp TEXT,
            prompt TEXT,
            success BOOLEAN,
            error_message TEXT,
            image_path TEXT,
            tokens_used INTEGER DEFAULT 0,
            processing_time REAL,
            FOREIGN KEY (user_id) REFERENCES user_stats (user_id)
        )
    """)
    
    conn.commit()
    conn.close()
    print("‚úÖ Database initialized with user statistics tables")

def get_or_create_user_stats(user_id: str):
    """Get or create user statistics record"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Check if user exists
    cursor.execute("SELECT * FROM user_stats WHERE user_id = ?", (user_id,))
    user = cursor.fetchone()
    
    if not user:
        # Create new user record
        now = datetime.now().isoformat()
        cursor.execute("""
            INSERT INTO user_stats 
            (user_id, total_generations, successful_generations, failed_generations, 
             total_errors, first_seen, last_active, total_tokens_used)
            VALUES (?, 0, 0, 0, 0, ?, ?, 0)
        """, (user_id, now, now))
        conn.commit()
        print(f"üìä Created new user stats for: {user_id}")
    
    conn.close()

def update_user_activity(user_id: str):
    """Update user s last active timestamp"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        UPDATE user_stats 
        SET last_active = ? 
        WHERE user_id = ?
    """, (datetime.now().isoformat(), user_id))
    
    conn.commit()
    conn.close()

def log_generation_attempt(user_id: str, session_id: str, prompt: str, 
                          success: bool, error_message: str = None, 
                          image_path: str = None, processing_time: float = 0.0):
    """Log generation attempt with full details"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Estimate tokens (rough calculation: 1 token ‚âà 4 characters)
    tokens_used = len(prompt) // 4 if prompt else 0
    
    # Log to generation_log
    cursor.execute("""
        INSERT INTO generation_log 
        (user_id, session_id, timestamp, prompt, success, error_message, 
         image_path, tokens_used, processing_time)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (user_id, session_id, datetime.now().isoformat(), prompt, 
          success, error_message, image_path, tokens_used, processing_time))
    
    # Update user stats
    if success:
        cursor.execute("""
            UPDATE user_stats 
            SET total_generations = total_generations + 1,
                successful_generations = successful_generations + 1,
                last_generation_time = ?,
                total_tokens_used = total_tokens_used + ?
            WHERE user_id = ?
        """, (datetime.now().isoformat(), tokens_used, user_id))
    else:
        cursor.execute("""
            UPDATE user_stats 
            SET total_generations = total_generations + 1,
                failed_generations = failed_generations + 1,
                last_generation_time = ?,
                total_tokens_used = total_tokens_used + ?
            WHERE user_id = ?
        """, (datetime.now().isoformat(), tokens_used, user_id))
    
    conn.commit()
    conn.close()
    print(f"üìä Logged generation: {user_id} - Success: {success}")



class ChatMessage(BaseModel):
    message: str
    user_id: str = "default"
    session_id: str = "default"

class EchoResponse(BaseModel):
    response: str
    image_path: Optional[str] = None
    story_state: Optional[Dict] = None
    action_taken: Optional[str] = None

# Keywords for creative content detection
CREATIVE_KEYWORDS = [
    'anime', 'manga', 'character', 'story', 'scene', 'draw', 'create', 'generate',
    'image', 'picture', 'video', 'animation', 'art', 'visual', 'illustration',
    'magical', 'fantasy', 'adventure', 'battle', 'romance', 'school', 'demon',
    'sword', 'princess', 'hero', 'villain', 'dragon', 'magic', 'spell',
    'sakura', 'naruto', 'goku', 'sailor', 'gundam', 'mecha'
]

SETTING_KEYWORDS = [
    'school', 'forest', 'castle', 'city', 'village', 'mountain', 'beach', 'space',
    'laboratory', 'battlefield', 'garden', 'temple', 'dungeon', 'sky', 'underwater',
    'tokyo', 'japan', 'academy', 'hospital', 'mansion', 'shop', 'restaurant'
]

CHARACTER_KEYWORDS = [
    'girl', 'boy', 'woman', 'man', 'student', 'teacher', 'warrior', 'mage',
    'princess', 'prince', 'hero', 'demon', 'angel', 'ninja', 'samurai',
    'pilot', 'scientist', 'doctor', 'artist', 'musician', 'chef'
]

def extract_story_elements(text: str) -> Dict[str, Any]:
    """Extract story elements from text"""
    text_lower = text.lower()

    # Extract characters
    characters = []
    for keyword in CHARACTER_KEYWORDS:
        if keyword in text_lower:
            characters.append(keyword)

    # Extract settings
    settings = []
    for keyword in SETTING_KEYWORDS:
        if keyword in text_lower:
            settings.append(keyword)

    # Extract names (capitalized words that aren't common words)
    names = re.findall(r'\b[A-Z][a-z]+\b', text)
    names = [name for name in names if name.lower() not in ['the', 'and', 'but', 'for', 'with', 'this', 'that']]

    return {
        'characters': characters,
        'settings': settings,
        'names': names,
        'raw_text': text
    }

def has_creative_intent(text: str) -> bool:
    """Check if text has creative/anime intent"""
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in CREATIVE_KEYWORDS)

def create_comfyui_workflow(prompt: str, character: str = "", setting: str = "") -> Dict:
    """Create ComfyUI workflow for image generation"""

    # Build enhanced prompt
    enhanced_prompt = f"masterpiece, best quality, highly detailed, {prompt}"
    if character:
        enhanced_prompt += f", {character}"
    if setting:
        enhanced_prompt += f", {setting}"
    enhanced_prompt += ", anime style, vibrant colors, professional artwork"

    # Generate unique filename
    timestamp = int(time.time())
    filename_prefix = f"echo_generated_{timestamp}"

    workflow = {
        "3": {
            "inputs": {
                "seed": int(time.time()) % 1000000,
                "steps": 20,
                "cfg": 8.0,
                "sampler_name": "euler",
                "scheduler": "normal",
                "denoise": 1.0,
                "model": ["4", 0],
                "positive": ["6", 0],
                "negative": ["7", 0],
                "latent_image": ["5", 0]
            },
            "class_type": "KSampler",
            "_meta": {"title": "KSampler"}
        },
        "4": {
            "inputs": {
                "ckpt_name": "deliberate_v2.safetensors"
            },
            "class_type": "CheckpointLoaderSimple",
            "_meta": {"title": "Load Checkpoint"}
        },
        "5": {
            "inputs": {
                "width": 512,
                "height": 512,
                "batch_size": 1
            },
            "class_type": "EmptyLatentImage",
            "_meta": {"title": "Empty Latent Image"}
        },
        "6": {
            "inputs": {
                "text": enhanced_prompt,
                "clip": ["4", 1]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Prompt)"}
        },
        "7": {
            "inputs": {
                "text": "nsfw, nude, bad quality, blurry, low resolution, watermark, text, signature",
                "clip": ["4", 1]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Negative)"}
        },
        "8": {
            "inputs": {
                "samples": ["3", 0],
                "vae": ["4", 2]
            },
            "class_type": "VAEDecode",
            "_meta": {"title": "VAE Decode"}
        },
        "9": {
            "inputs": {
                "filename_prefix": filename_prefix,
                "images": ["8", 0]
            },
            "class_type": "SaveImage",
            "_meta": {"title": "Save Image"}
        }
    }

    return workflow

async def generate_image_comfyui(prompt: str, character: str = "", setting: str = "") -> Optional[str]:
    """Actually generate image through ComfyUI API"""
    try:
        print(f"üé® Generating image: {prompt} | Character: {character} | Setting: {setting}")

        # Create workflow
        workflow = create_comfyui_workflow(prompt, character, setting)

        # Submit to ComfyUI
        comfyui_url = "http://localhost:8188"

        # Queue the prompt
        queue_response = requests.post(f"{comfyui_url}/prompt", json={"prompt": workflow})

        if queue_response.status_code != 200:
            print(f"‚ùå Failed to queue prompt: {queue_response.status_code}")
            return None

        queue_data = queue_response.json()
        prompt_id = queue_data.get("prompt_id")

        if not prompt_id:
            print("‚ùå No prompt_id received")
            return None

        print(f"‚úÖ Queued prompt with ID: {prompt_id}")

        # Wait for completion and get result
        max_wait = 60  # 60 seconds timeout
        start_time = time.time()

        while time.time() - start_time < max_wait:
            try:
                # Check queue status
                queue_status = requests.get(f"{comfyui_url}/queue")
                if queue_status.status_code == 200:
                    queue_info = queue_status.json()

                    # Check if our prompt is still in queue
                    running = queue_info.get("queue_running", [])
                    pending = queue_info.get("queue_pending", [])

                    still_in_queue = any(item[1] == prompt_id for item in running + pending)

                    if not still_in_queue:
                        print(f"‚úÖ Prompt {prompt_id} completed!")
                        break

                await asyncio.sleep(2)

            except Exception as e:
                print(f"‚ö†Ô∏è Error checking queue: {e}")
                await asyncio.sleep(2)

        # Look for generated images
        output_dir = "/home/patrick/ComfyUI/output"

        # Find files that match our prefix and were created recently
        timestamp = int(time.time())
        possible_files = []

        if os.path.exists(output_dir):
            for file in os.listdir(output_dir):
                # ComfyUI adds _00001_ suffix to filenames, so check for our prefix
                if file.startswith("echo_generated_") and file.endswith((".png", ".jpg", ".jpeg")):
                    file_path = os.path.join(output_dir, file)
                    file_time = os.path.getmtime(file_path)

                    # If file was created in the last 2 minutes
                    if timestamp - file_time < 120:
                        possible_files.append((file_path, file_time))

        if possible_files:
            # Return the most recently created file
            latest_file = max(possible_files, key=lambda x: x[1])
            image_path = latest_file[0]
            print(f"‚úÖ Generated image: {image_path}")
            return image_path
        else:
            print("‚ùå No generated image found")
            return None

    except Exception as e:
        print(f"‚ùå Error generating image: {e}")
        return None


# Apple Music integration functions
import requests

def has_apple_music_intent(text: str) -> bool:
    """Check if the user is asking for Apple Music functionality"""
    text_lower = text.lower()

    music_keywords = [
        'playlist', 'playlists', 'apple music', 'music', 'songs', 'tracks',
        'my music', 'my playlists', 'pull playlist', 'get playlist',
        'fetch playlist', 'show playlist', 'list playlist'
    ]

    return any(keyword in text_lower for keyword in music_keywords)

def call_apple_music_service(action: str, query: str = None) -> dict:
    """Call the Apple Music OAuth service"""
    try:
        if action == "get_playlists":
            response = requests.get("http://localhost:8401/api/health", timeout=5)
            if response.status_code == 200:
                return {
                    "success": True,
                    "message": "Apple Music service is available. To access your personal playlists, please authenticate at https://***REMOVED***/api/apple-music/",
                    "action": "redirect_to_auth"
                }
            else:
                return {
                    "success": False,
                    "message": "Apple Music service is not responding",
                    "error": f"Status code: {response.status_code}"
                }

        elif action == "search_catalog" and query:
            token_response = requests.get("http://localhost:8401/developer-token", timeout=5)
            if token_response.status_code == 200:
                token_data = token_response.json()
                token = token_data.get('token')

                if token:
                    headers = {
                        'Authorization': f'Bearer {token}',
                        'User-Agent': 'Tower Echo Brain'
                    }

                    search_url = "https://api.music.apple.com/v1/catalog/us/search"
                    params = {
                        'term': query,
                        'types': 'songs,playlists',
                        'limit': 5
                    }

                    search_response = requests.get(search_url, headers=headers, params=params, timeout=10)

                    if search_response.status_code == 200:
                        search_data = search_response.json()
                        return {
                            "success": True,
                            "message": f"Found music for '{query}'",
                            "data": search_data,
                            "action": "catalog_search"
                        }
                    else:
                        return {
                            "success": False,
                            "message": "Apple Music search failed",
                            "error": f"Search status: {search_response.status_code}"
                        }

        return {
            "success": False,
            "message": f"Unknown Apple Music action: {action}"
        }

    except Exception as e:
        return {
            "success": False,
            "message": "Apple Music integration error",
            "error": str(e)
        }

def process_apple_music_request(text: str) -> dict:
    """Process Apple Music requests and return appropriate response"""
    text_lower = text.lower()

    if any(word in text_lower for word in ['playlist', 'playlists', 'my music', 'my playlists']):
        return call_apple_music_service("get_playlists")

    elif any(word in text_lower for word in ['search', 'find', 'look for']) and 'music' in text_lower:
        import re
        quoted_match = re.search(r'"([^"]+)"', text)
        if quoted_match:
            query = quoted_match.group(1)
        else:
            for_match = re.search(r'\b(?:for|search)\s+(.+?)(?:\s|$)', text_lower)
            if for_match:
                query = for_match.group(1).strip()
            else:
                query = "popular music"

        return call_apple_music_service("search_catalog", query)

    else:
        return call_apple_music_service("get_playlists")

@app.post("/api/echo/chat", response_model=EchoResponse)
async def chat_endpoint(message: ChatMessage):
    """Main chat endpoint with image generation"""

    user_id = message.user_id
    session_id = message.session_id
    text = message.message
    start_time = time.time()

    # Ensure user stats exist and update activity
    get_or_create_user_stats(user_id)
    update_user_activity(user_id)

    # Get or create story state
    state_key = f"{user_id}_{session_id}"
    if state_key not in story_states:
        story_states[state_key] = {
            'characters': [],
            'settings': [],
            'names': [],
            'history': [],
            'last_update': datetime.now().isoformat()
        }

    story_state = story_states[state_key]

    # Add to history
    story_state['history'].append({
        'message': text,
        'timestamp': datetime.now().isoformat()
    })

    # Extract story elements

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    elements = extract_story_elements(text)

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )


    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    # Update story state

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    story_state['characters'].extend(elements['characters'])

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    story_state['settings'].extend(elements['settings'])

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    story_state['names'].extend(elements['names'])

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    story_state['last_update'] = datetime.now().isoformat()

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )


    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    # Remove duplicates

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    story_state['characters'] = list(set(story_state['characters']))

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    story_state['settings'] = list(set(story_state['settings']))

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )
    story_state['names'] = list(set(story_state['names']))

    # Check for Apple Music requests FIRST
    if has_apple_music_intent(text):
        apple_music_result = process_apple_music_request(text)
        
        if apple_music_result["success"]:
            response_text = apple_music_result["message"]
            
            # If we have catalog search results, format them nicely
            if apple_music_result.get("action") == "catalog_search" and apple_music_result.get("data"):
                search_data = apple_music_result["data"]
                if "results" in search_data:
                    response_text += "\n\nüéµ Found:"
                    
                    if "songs" in search_data["results"]:
                        songs = search_data["results"]["songs"]["data"][:3]
                        for song in songs:
                            artist = song["attributes"]["artistName"]
                            title = song["attributes"]["name"]
                            response_text += f"\n‚ô™ {title} by {artist}"
                    
                    if "playlists" in search_data["results"]:
                        playlists = search_data["results"]["playlists"]["data"][:3]
                        for playlist in playlists:
                            name = playlist["attributes"]["name"]
                            curator = playlist["attributes"].get("curatorName", "Apple Music")
                            response_text += f"\nüìö {name} (by {curator})"
        else:
            response_text = f"‚ùå {apple_music_result["message"]}"
            if "error" in apple_music_result:
                response_text += f" ({apple_music_result["error"]})"
        
        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
        return EchoResponse(
            response=response_text,
            generated_image=None,
            story_state=story_state,
            processing_time=time.time() - start_time,
            action_taken="apple_music_integration"
        )

    # Check if we should generate an image
    should_generate = False
    image_path = None
    action_taken = None

    if has_creative_intent(text):
        # Check if we have enough story elements
        has_character = len(story_state['characters']) > 0 or len(story_state['names']) > 0
        has_setting = len(story_state['settings']) > 0

        if has_character and has_setting:
            should_generate = True
            action_taken = "GENERATING_IMAGE"

            # Build generation prompt
            character = story_state['names'][0] if story_state['names'] else story_state['characters'][0]
            setting = story_state['settings'][0]

            # Generate image
            image_path = await generate_image_comfyui(text, character, setting)

            if image_path:
                action_taken = "IMAGE_GENERATED"
                processing_time = time.time() - start_time
                log_generation_attempt(user_id, session_id, text, True, None, image_path, processing_time)
            else:
                action_taken = "IMAGE_GENERATION_FAILED"
                processing_time = time.time() - start_time
                log_generation_attempt(user_id, session_id, text, False, "ComfyUI generation failed", None, processing_time)

    # Create response
    if should_generate and image_path:
        response_text = f"Created {character} in {setting}! Image saved successfully."
    elif should_generate and not image_path:
        response_text = f"I tried to generate an image but encountered an issue. Let me gather more details about your story."
    elif has_creative_intent(text):
        missing = []
        if not (story_state['characters'] or story_state['names']):
            missing.append("a character")
        if not story_state['settings']:
            missing.append("a setting/location")

        if missing:
            response_text = f"I'm building your story! I still need {' and '.join(missing)} to create an image. Tell me more!"
        else:
            response_text = "I'm ready to create an image for your story!"
    else:
                # Provide contextual responses
        if "hello" in text or "hi" in text:
            response_text = "Hello! I can generate anime images. Try: Generate a samurai warrior"
        elif "help" in text:
            response_text = "I can create images! Tell me a character and setting, then say generate"
        else:
            response_text = f"Tell me what to create. Example: Generate a dragon in space"

        # AgenticPersona Voice Enhancement        voice_enhancement = await enhance_chat_with_voice(response_text, {"voice_enabled": False})        if voice_enhancement.get("voice_available"):            extra_data["voice"] = voice_enhancement
    return EchoResponse(
        response=response_text,
        image_path=image_path,
        story_state=story_state,
        action_taken=action_taken
    )


@app.get("/api/echo/stats/global")
async def get_global_stats():
    """Get global statistics for admin overview"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Total users
        cursor.execute("SELECT COUNT(*) FROM user_stats")
        total_users = cursor.fetchone()[0]
        
        # Total generations
        cursor.execute("SELECT SUM(total_generations) FROM user_stats")
        total_generations = cursor.fetchone()[0] or 0
        
        # Total successful generations
        cursor.execute("SELECT SUM(successful_generations) FROM user_stats")
        total_successful = cursor.fetchone()[0] or 0
        
        # Total failed generations
        cursor.execute("SELECT SUM(failed_generations) FROM user_stats")
        total_failed = cursor.fetchone()[0] or 0
        
        # Active users (last 24 hours)
        yesterday = (datetime.now() - timedelta(days=1)).isoformat()
        cursor.execute("SELECT COUNT(*) FROM user_stats WHERE last_active > ?", (yesterday,))
        active_users_24h = cursor.fetchone()[0]
        
        # Most active users (top 5)
        cursor.execute("""
            SELECT user_id, total_generations, successful_generations, last_active
            FROM user_stats 
            ORDER BY total_generations DESC 
            LIMIT 5
        """)
        top_users = [dict(zip([desc[0] for desc in cursor.description], row)) 
                    for row in cursor.fetchall()]
        
        conn.close()
        
        # Calculate metrics
        success_rate = (total_successful / total_generations * 100) if total_generations > 0 else 0
        error_rate = (total_failed / total_generations * 100) if total_generations > 0 else 0
        
        return {
            "overview": {
                "total_users": total_users,
                "active_users_24h": active_users_24h,
                "total_generations": total_generations,
                "total_successful_generations": total_successful,
                "total_failed_generations": total_failed
            },
            "metrics": {
                "global_success_rate_percentage": round(success_rate, 2),
                "global_error_rate_percentage": round(error_rate, 2),
                "average_generations_per_user": round(total_generations / total_users, 2) if total_users > 0 else 0
            },
            "top_users": top_users,
            "generated_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error retrieving global stats: {str(e)}")

@app.get("/api/echo/stats/{user_id}")
async def get_user_stats(user_id: str = Path(..., description="User ID to get stats for")):
    """Get comprehensive statistics for a specific user"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Get basic user stats
        cursor.execute("SELECT * FROM user_stats WHERE user_id = ?", (user_id,))
        user_row = cursor.fetchone()
        
        if not user_row:
            raise HTTPException(status_code=404, detail="User not found")
        
        # Convert to dict
        columns = [desc[0] for desc in cursor.description]
        user_stats = dict(zip(columns, user_row))
        
        # Calculate success rate
        total_gens = user_stats['total_generations']
        success_rate = (user_stats['successful_generations'] / total_gens * 100) if total_gens > 0 else 0
        error_rate = (user_stats['failed_generations'] / total_gens * 100) if total_gens > 0 else 0
        
        # Get recent generation history (last 10)
        cursor.execute("""
            SELECT timestamp, prompt, success, image_path, processing_time
            FROM generation_log 
            WHERE user_id = ? 
            ORDER BY timestamp DESC 
            LIMIT 10
        """, (user_id,))
        recent_generations = [dict(zip([desc[0] for desc in cursor.description], row)) 
                            for row in cursor.fetchall()]
        
        # Get usage patterns (generations per day for last 7 days)
        seven_days_ago = (datetime.now() - timedelta(days=7)).isoformat()
        cursor.execute("""
            SELECT DATE(timestamp) as date, COUNT(*) as count
            FROM generation_log 
            WHERE user_id = ? AND timestamp > ?
            GROUP BY DATE(timestamp)
            ORDER BY date
        """, (user_id, seven_days_ago))
        daily_usage = [dict(zip([desc[0] for desc in cursor.description], row)) 
                      for row in cursor.fetchall()]
        
        conn.close()
        
        return {
            "user_id": user_id,
            "basic_stats": user_stats,
            "calculated_metrics": {
                "success_rate_percentage": round(success_rate, 2),
                "error_rate_percentage": round(error_rate, 2),
                "average_tokens_per_generation": round(user_stats['total_tokens_used'] / total_gens, 2) if total_gens > 0 else 0
            },
            "recent_generations": recent_generations,
            "usage_patterns": {
                "daily_usage_last_7_days": daily_usage
            },
            "generated_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error retrieving stats: {str(e)}")

@app.get("/api/echo/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "Echo Brain Working",
        "timestamp": datetime.now().isoformat(),
        "comfyui_status": "checking"
    }

@app.get("/api/echo/story/{user_id}/{session_id}")
async def get_story_state(user_id: str, session_id: str):
    """Get current story state"""
    state_key = f"{user_id}_{session_id}"
    if state_key in story_states:
        return story_states[state_key]
    else:
        return {"error": "No story state found"}


@app.get("/api/echo/status")
async def get_status():
    """Status endpoint for dashboard integration"""
    from datetime import datetime, timedelta
    return {
        "status": "online",
        "service": "echo-brain", 
        "current_thought": "Monitoring Tower services",
        "thought_type": "analysis",
        "response_time": 0.12,
        "recent_queries": len(story_states) if 'story_states' in globals() else 0,
        "last_activity": datetime.utcnow().isoformat()
    }


# Import UploadFile for voice endpointsfrom fastapi import UploadFile, File
if __name__ == "__main__":

# AgenticPersona Voice Endpoints
@app.post("/api/echo/voice/chat")
async def voice_chat_endpoint(audio_file: UploadFile = File(...)):
    """Voice chat with agenticPersona support"""
    try:
        # Process voice input
        audio_data = await audio_file.read()
        voice_input = await agentic_voice_manager.process_voice_command(audio_data)

        if "error" in voice_input:
            return {"error": voice_input["error"]}

        # Get text and process through Echo
        text_message = voice_input["text"]
        context = voice_input["context"]
        context["voice_enabled"] = True

        # Process through normal Echo chat logic
        chat_message = ChatMessage(
            message=text_message,
            user_id="voice_user",
            session_id="voice_session"
        )

        # Get Echo's normal response
        echo_response = await chat_endpoint(chat_message)

        # Enhance with voice output
        voice_enhancement = await enhance_chat_with_voice(echo_response.message, context)

        return {
            "input": voice_input,
            "echo_response": echo_response,
            "voice_enhancement": voice_enhancement,
            "agenticPersona": True
        }

    except Exception as e:
        logger.error(f"Voice chat error: {e}")
        return {"error": str(e)}

@app.post("/api/echo/voice/synthesize")
async def voice_synthesize_endpoint(request: dict):
    """Synthesize voice with character persona"""
    try:
        text = request.get("text", "")
        character_name = request.get("character", "echo_default")
        context = request.get("context", {})

        # Convert character name to enum
        try:
            character = VoiceCharacter(character_name)
        except ValueError:
            character = VoiceCharacter.ECHO

        # Synthesize with persona
        result = await agentic_voice_manager.synthesize_voice_response(
            text, character, context
        )

        return result

    except Exception as e:
        logger.error(f"Voice synthesis error: {e}")
        return {"error": str(e)}

@app.post("/api/echo/voice/character-singing")
async def character_singing_endpoint(request: dict):
    """Generate character singing with agenticPersona"""
    try:
        lyrics = request.get("lyrics", "")
        character_name = request.get("character", "sakura")
        backing_track = request.get("backing_track")

        try:
            character = VoiceCharacter(character_name)
        except ValueError:
            character = VoiceCharacter.SAKURA

        result = await agentic_voice_manager.create_character_singing(
            lyrics, character, backing_track
        )

        return result

    except Exception as e:
        logger.error(f"Character singing error: {e}")
        return {"error": str(e)}

@app.get("/api/echo/voice/characters")
async def get_voice_characters():
    """Get available agenticPersona voice characters"""
    return {
        "characters": {
            char.value: {
                "name": char.value,
                "personality": agentic_voice_manager.character_profiles[char]["personality"],
                "specialties": agentic_voice_manager.character_profiles[char]["specialties"],
                "voice_style": agentic_voice_manager.character_profiles[char]["voice_style"]
            }
            for char in VoiceCharacter
        },
        "agenticPersona": True
    }

    print("üöÄ Starting Echo Brain Working Service with Stats on port 8309")
    print("üé® ComfyUI integration enabled")
    print("üìä Story state tracking enabled")
    print("üìà User statistics tracking enabled")
    
    # Initialize database
    init_database()
    uvicorn.run(app, host="0.0.0.0", port=8309)
# ============= SELF-REPAIR SYSTEM =============
import subprocess
from pathlib import Path

async def check_and_repair_services():
    """Echo's self-repair capability"""
    try:
        # Check Telegram bot health
        telegram_check = subprocess.run(
            "systemctl is-active patricksechobot.service",
            shell=True, capture_output=True, text=True
        )
        
        if telegram_check.stdout.strip() != "active":
            print("üîß Echo: Telegram bot down, fixing it...")
            subprocess.run("sudo systemctl restart patricksechobot.service", shell=True)
            return {"repaired": "telegram_bot"}
        
        # Check for 409 errors (multiple instances)
        error_check = subprocess.run(
            "tail -50 /opt/patricks-echo-bot/bot.log | grep -c 409",
            shell=True, capture_output=True, text=True
        )
        
        if int(error_check.stdout.strip() or 0) > 10:
            print("üîß Echo: Multiple Telegram instances detected, fixing...")
            subprocess.run("pkill -f patricksecho", shell=True)
            subprocess.run("sudo systemctl restart patricksechobot.service", shell=True)
            return {"repaired": "telegram_conflicts"}
            
        return {"status": "all_healthy"}
    except Exception as e:
        return {"error": str(e)}

# Add self-repair endpoint
@app.post("/api/echo/self-repair")
async def trigger_self_repair():
    """Manually trigger Echo's self-repair"""
    result = await check_and_repair_services()
    return {
        "message": "Self-repair completed",
        "result": result,
        "timestamp": datetime.now().isoformat()
    }

# Auto-repair loop (runs every 5 minutes)
async def auto_repair_loop():
    while True:
        await asyncio.sleep(300)  # 5 minutes
        result = await check_and_repair_services()
        if result.get("repaired"):
            print(f"‚úÖ Echo auto-repaired: {result['repaired']}")

# Start auto-repair in background
asyncio.create_task(auto_repair_loop())
